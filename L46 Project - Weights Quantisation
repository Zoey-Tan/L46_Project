{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18zsRW8k5CyDBocX24ykEm9slHQFpjWp4","timestamp":1705855894362}],"gpuType":"V100","mount_file_id":"1wVZH3xfnhhfFseRiUwIAv3wvrKGV12MJ","authorship_tag":"ABX9TyP7aBVW17Z8uGXbWMM/+RaC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torcheval\n","!pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yRpCn445VUzq","executionInfo":{"status":"ok","timestamp":1705915106419,"user_tz":0,"elapsed":22482,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"06c5a372-3c67-42a3-c068-1fcce83ecf6c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\n","Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torcheval.metrics.functional import multiclass_precision, multiclass_recall, multiclass_f1_score, multiclass_auprc, multiclass_confusion_matrix, multiclass_precision_recall_curve"],"metadata":{"id":"D1iL_g6mo5rg","executionInfo":{"status":"ok","timestamp":1705915110736,"user_tz":0,"elapsed":4321,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0')\n","#device = torch.device(\"cpu\")"],"metadata":{"id":"MSb-8zd-zjFJ","executionInfo":{"status":"ok","timestamp":1705915110736,"user_tz":0,"elapsed":6,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class BaselineLSTM(nn.Module):\n","    def __init__(self):\n","        super(BaselineLSTM, self).__init__()\n","        self.lstm1 = nn.LSTM(input_size=193, hidden_size=1024, batch_first=True)\n","        self.d1 = nn.Dropout(p=0.2)\n","        self.lstm2 = nn.LSTM(input_size=1024, hidden_size=512, batch_first=True)\n","        self.d2 = nn.Dropout(p=0.2)\n","        self.lstm3 = nn.LSTM(input_size=512, hidden_size=256, batch_first=True)\n","        self.d3 = nn.Dropout(p=0.2)\n","        self.lstm4 = nn.LSTM(input_size=256, hidden_size=128, batch_first=True)\n","        self.d4 = nn.Dropout(p=0.2)\n","        self.lstm5 = nn.LSTM(input_size=128, hidden_size=64, batch_first=True)\n","        self.d5 = nn.Dropout(p=0.2)\n","        self.maxpool = nn.MaxPool1d(2)\n","        self.f = nn.Flatten()\n","        self.fc1 = nn.Linear(7040, 100)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(100, 6)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        x, (final_hidden_state, final_cell_state) = self.lstm1(x)\n","        x = self.d1(x)\n","        x, (final_hidden_state, final_cell_state) = self.lstm2(x)\n","        x = self.d2(x)\n","        x, (final_hidden_state, final_cell_state) = self.lstm3(x)\n","        x = self.d3(x)\n","        x, (final_hidden_state, final_cell_state) = self.lstm4(x)\n","        x = self.d4(x)\n","        x, (final_hidden_state, final_cell_state) = self.lstm5(x)\n","        x = self.d5(x)\n","        x = self.maxpool(x.permute(0,2,1)).permute(0,2,1)\n","        x = self.f(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.softmax(x)\n","        return x\n"],"metadata":{"id":"8_fnInSDSWPw","executionInfo":{"status":"ok","timestamp":1705915110736,"user_tz":0,"elapsed":5,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"zCeqo7RTE8f8","executionInfo":{"status":"ok","timestamp":1705915111118,"user_tz":0,"elapsed":387,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"outputs":[],"source":["with open('/content/drive/MyDrive/l46_dataset/X_train.npy', 'rb') as f:\n","  X_train = np.load(f)\n","with open('/content/drive/MyDrive/l46_dataset/Y_train.npy', 'rb') as f:\n","  y_train = np.load(f)\n","with open('/content/drive/MyDrive/l46_dataset/X_test.npy', 'rb') as f:\n","  X_test = np.load(f)\n","with open('/content/drive/MyDrive/l46_dataset/Y_test.npy', 'rb') as f:\n","  y_test = np.load(f)"]},{"cell_type":"code","source":["X_train_tensor = torch.Tensor(X_train).to(device)\n","X_test_tensor = torch.Tensor(X_test).to(device)\n","y_train_tensor = torch.Tensor(np.argmax(y_train, axis=-1).astype(int)).long().to(device)\n","y_test_tensor = torch.Tensor(np.argmax(y_test, axis=-1).astype(int)).long().to(device)\n","\n","train_set = TensorDataset(X_train_tensor, y_train_tensor)\n","test_set = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","train_dataloader = DataLoader(train_set, batch_size=32)\n","test_dataloader = DataLoader(test_set, batch_size=32)"],"metadata":{"id":"UaHAdmlfYgja","executionInfo":{"status":"ok","timestamp":1705915111459,"user_tz":0,"elapsed":342,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["X_train_tensor.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aElS2bzdzQ9r","executionInfo":{"status":"ok","timestamp":1705915111459,"user_tz":0,"elapsed":2,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"3c4db299-32ec-4231-ba6f-d9893efa536e"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1004, 221, 193])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def train(model, epoch, loss_fn, optimizer):\n","  history = {'train_loss':[], 'train_accuracy':[], 'train_precision':[], 'train_recall':[], 'train_f1':[],\n","             'val_loss':[], 'val_accuracy':[], 'val_precision':[], 'val_recall':[], 'val_f1':[]}\n","\n","  for epoch in range(epoch):\n","\n","      model.train(True)\n","      running_loss = 0.0\n","      correct = 0\n","      output_list = None\n","      label_list = None\n","      for i, data in enumerate(train_dataloader, 0):\n","\n","          inputs, labels = data\n","          optimizer.zero_grad()\n","          outputs = model(inputs)\n","          labels = labels.long()\n","          loss = loss_fn(torch.log(outputs), labels)\n","          loss.backward()\n","          print(loss)\n","          #print(model(inputs))\n","          optimizer.step()\n","          #print('After optimisation',model(inputs))\n","          running_loss += loss.item()\n","          correct += (torch.argmax(outputs, dim=-1) == labels).float().sum()\n","          output_list = outputs if output_list is None else torch.cat((output_list,outputs),0)\n","          label_list = labels if label_list is None else torch.cat((label_list,labels),0)\n","\n","      avg_loss = running_loss / (i + 1)\n","      accuracy = correct / len(train_set)\n","      precision = multiclass_precision(output_list, label_list, num_classes=6, average='macro')\n","      recall = multiclass_recall(output_list, label_list, num_classes=6, average='macro')\n","      f1_score = multiclass_f1_score(output_list, label_list, num_classes=6, average='macro')\n","\n","      running_vloss = 0.0\n","      vcorrect = 0\n","      model.eval()\n","\n","      voutput_list = None\n","      vlabel_list = None\n","      with torch.no_grad():\n","          for i, vdata in enumerate(test_dataloader):\n","              vinputs, vlabels = vdata\n","              voutputs = model(vinputs)\n","              vloss = loss_fn(torch.log(voutputs), vlabels)\n","              running_vloss += vloss.item()\n","              vcorrect += (torch.argmax(voutputs, dim=-1) == vlabels).float().sum()\n","              voutput_list = voutputs if voutput_list is None else torch.cat((voutput_list,voutputs),0)\n","              vlabel_list = vlabels if vlabel_list is None else torch.cat((vlabel_list,vlabels),0)\n","\n","      avg_vloss = running_vloss / (i + 1)\n","      vaccuracy = vcorrect / len(test_set)\n","      vprecision = multiclass_precision(voutput_list, vlabel_list, num_classes=6, average='macro')\n","      vrecall = multiclass_recall(voutput_list, vlabel_list, num_classes=6, average='macro')\n","      vf1_score = multiclass_f1_score(voutput_list, vlabel_list, num_classes=6, average='macro')\n","\n","      print('Epoch {}-- Train loss:{:.2f} accuracy:{:.2f} precision:{:.2f} recall:{:.2f} f1:{:.2f}'.format(epoch, avg_loss, accuracy, precision, recall, f1_score))\n","      print('Epoch {}-- Valid loss:{:.2f} accuracy:{:.2f} precision:{:.2f} recall:{:.2f} f1:{:.2f}'.format(epoch, avg_vloss, vaccuracy, vprecision, vrecall, vf1_score))\n","      history['train_loss'].append(avg_loss)\n","      history['train_accuracy'].append(accuracy)\n","      history['train_precision'].append(precision)\n","      history['train_recall'].append(recall)\n","      history['train_f1'].append(f1_score)\n","      history['val_loss'].append(avg_vloss)\n","      history['val_accuracy'].append(vaccuracy)\n","      history['val_precision'].append(vprecision)\n","      history['val_recall'].append(vrecall)\n","      history['val_f1'].append(vf1_score)\n","\n","  return history\n"],"metadata":{"id":"VXHLOQoOXU7H","executionInfo":{"status":"ok","timestamp":1705915111459,"user_tz":0,"elapsed":1,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def model_evaluate(model):\n","    model.eval()\n","    voutput_list = None\n","    vlabel_list = None\n","    running_vloss = 0.0\n","    vcorrect = 0\n","    times = []\n","    with torch.no_grad():\n","        for i, vdata in enumerate(test_dataloader):\n","            vinputs, vlabels = vdata\n","            vinputs = vinputs\n","            vlabels = vlabels\n","            start = time.time()\n","            voutputs = model(vinputs)\n","            end = time.time()\n","            times.append(end-start)\n","            #vloss = loss_fn(torch.log(voutputs), vlabels)\n","            #running_vloss += vloss.item()\n","            vcorrect += (torch.argmax(voutputs, dim=-1) == vlabels).float().sum()\n","            voutput_list = voutputs if voutput_list is None else torch.cat((voutput_list,voutputs),0)\n","            vlabel_list = vlabels if vlabel_list is None else torch.cat((vlabel_list,vlabels),0)\n","\n","    print(np.array(times).mean())\n","    avg_vloss = running_vloss / (i + 1)\n","    vaccuracy = vcorrect / len(test_set)\n","    vprecision = multiclass_precision(voutput_list, vlabel_list, num_classes=6, average='macro')\n","    vrecall = multiclass_recall(voutput_list, vlabel_list, num_classes=6, average='macro')\n","    vf1_score = multiclass_f1_score(voutput_list, vlabel_list, num_classes=6, average='macro')\n","    vauprc = multiclass_auprc(voutput_list, vlabel_list, num_classes=6, average='macro')\n","    vconfusion_matrix = multiclass_confusion_matrix(voutput_list, vlabel_list, num_classes=6, normalize=\"true\")\n","    vprc = multiclass_precision_recall_curve(voutput_list, vlabel_list, num_classes=6)\n","    analysis = {}\n","    analysis[\"loss\"] = avg_vloss\n","    analysis[\"accuracy\"] = vaccuracy\n","    analysis[\"precision\"] = vprecision\n","    analysis[\"recall\"] = vrecall\n","    analysis[\"f1_score\"] = vf1_score\n","    analysis[\"auprc\"] = vauprc\n","    analysis[\"confusion_matrix\"] = vconfusion_matrix\n","    analysis[\"prc\"] = vprc\n","    return analysis"],"metadata":{"id":"GZ5qPQV-FjDm","executionInfo":{"status":"ok","timestamp":1705915111795,"user_tz":0,"elapsed":3,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def model_size(model):\n","    param_size = 0\n","    for param in model.parameters():\n","        param_size += param.nelement() * param.element_size()\n","    buffer_size = 0\n","    for buffer in model.buffers():\n","        buffer_size += buffer.nelement() * buffer.element_size()\n","\n","    size_all_mb = (param_size + buffer_size) / 1024**2\n","    print('model size: {:.3f}MB'.format(size_all_mb))\n","    return size_all_mb"],"metadata":{"id":"DrWWFDwhsA12","executionInfo":{"status":"ok","timestamp":1705915111795,"user_tz":0,"elapsed":2,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import os\n","def print_size_of_model(model):\n","    torch.save(model.state_dict(), \"temp.p\")\n","    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n","    os.remove('temp.p')"],"metadata":{"id":"-D9MFPf8utPO","executionInfo":{"status":"ok","timestamp":1705915111795,"user_tz":0,"elapsed":2,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["baseline_model = BaselineLSTM().to(device)\n","baseline_model.load_state_dict(torch.load('baselineLSTM_0122.pth'))\n","weights = torch.Tensor([20,20,1,10,10,10]).to(device)\n","#weights = torch.Tensor([1,1,1,1,1,1]).to(device)\n","loss_fn = nn.NLLLoss(weight=weights)\n","print_size_of_model(baseline_model)\n","model_evaluate(baseline_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"la97oOxiNtbr","executionInfo":{"status":"ok","timestamp":1705911577447,"user_tz":0,"elapsed":15375,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"4c66e8f1-3411-4e59-ccef-7e514210a0d0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Size (MB): 39.539514\n","1.6074984338548448\n"]},{"output_type":"execute_result","data":{"text/plain":["{'loss': 0.0,\n"," 'accuracy': tensor(0.9489),\n"," 'precision': tensor(0.9254),\n"," 'recall': tensor(0.9347),\n"," 'f1_score': tensor(0.9279),\n"," 'auprc': tensor(0.9637),\n"," 'confusion_matrix': tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0000, 0.8462, 0.0000, 0.0769, 0.0769, 0.0000],\n","         [0.0000, 0.0000, 0.9607, 0.0112, 0.0169, 0.0112],\n","         [0.0000, 0.0000, 0.0476, 0.9524, 0.0000, 0.0000],\n","         [0.0000, 0.0000, 0.0345, 0.0000, 0.8966, 0.0690],\n","         [0.0000, 0.0000, 0.0476, 0.0000, 0.0000, 0.9524]]),\n"," 'prc': ([tensor([0.0438, 0.0440, 0.0441, 0.0444, 0.0446, 0.0448, 0.0449, 0.0451, 0.0453,\n","           0.0455, 0.0456, 0.0458, 0.0460, 0.0462, 0.0463, 0.0465, 0.0467, 0.0469,\n","           0.0471, 0.0474, 0.0476, 0.0478, 0.0480, 0.0482, 0.0484, 0.0486, 0.0488,\n","           0.0490, 0.0492, 0.0496, 0.0498, 0.0500, 0.0502, 0.0504, 0.0506, 0.0508,\n","           0.0511, 0.0513, 0.0515, 0.0517, 0.0519, 0.0522, 0.0524, 0.0526, 0.0529,\n","           0.0531, 0.0533, 0.0536, 0.0538, 0.0541, 0.0543, 0.0545, 0.0548, 0.0550,\n","           0.0553, 0.0556, 0.0558, 0.0561, 0.0563, 0.0566, 0.0569, 0.0571, 0.0574,\n","           0.0577, 0.0580, 0.0583, 0.0585, 0.0588, 0.0591, 0.0594, 0.0597, 0.0600,\n","           0.0603, 0.0606, 0.0609, 0.0612, 0.0615, 0.0619, 0.0622, 0.0625, 0.0628,\n","           0.0632, 0.0635, 0.0638, 0.0642, 0.0645, 0.0649, 0.0652, 0.0656, 0.0659,\n","           0.0663, 0.0667, 0.0670, 0.0674, 0.0678, 0.0682, 0.0686, 0.0690, 0.0694,\n","           0.0698, 0.0702, 0.0706, 0.0710, 0.0714, 0.0719, 0.0723, 0.0727, 0.0732,\n","           0.0736, 0.0741, 0.0745, 0.0750, 0.0755, 0.0759, 0.0764, 0.0769, 0.0774,\n","           0.0779, 0.0784, 0.0789, 0.0795, 0.0800, 0.0805, 0.0811, 0.0816, 0.0822,\n","           0.0828, 0.0833, 0.0839, 0.0845, 0.0851, 0.0857, 0.0863, 0.0870, 0.0876,\n","           0.0889, 0.0896, 0.0902, 0.0909, 0.0916, 0.0923, 0.0930, 0.0938, 0.0945,\n","           0.0952, 0.0960, 0.0968, 0.0976, 0.0984, 0.0992, 0.1000, 0.1008, 0.1017,\n","           0.1026, 0.1034, 0.1043, 0.1053, 0.1062, 0.1071, 0.1081, 0.1091, 0.1101,\n","           0.1111, 0.1121, 0.1132, 0.1143, 0.1154, 0.1165, 0.1176, 0.1188, 0.1200,\n","           0.1212, 0.1224, 0.1237, 0.1250, 0.1263, 0.1277, 0.1290, 0.1304, 0.1319,\n","           0.1348, 0.1364, 0.1379, 0.1395, 0.1412, 0.1429, 0.1446, 0.1463, 0.1481,\n","           0.1500, 0.1538, 0.1558, 0.1579, 0.1600, 0.1622, 0.1644, 0.1667, 0.1690,\n","           0.1714, 0.1739, 0.1765, 0.1791, 0.1818, 0.1846, 0.1875, 0.1905, 0.1935,\n","           0.1967, 0.2000, 0.2034, 0.2069, 0.2105, 0.2143, 0.2182, 0.2222, 0.2264,\n","           0.2308, 0.2353, 0.2400, 0.2449, 0.2500, 0.2553, 0.2609, 0.2667, 0.2727,\n","           0.2791, 0.2857, 0.3000, 0.3077, 0.3158, 0.3243, 0.3333, 0.3429, 0.3529,\n","           0.3636, 0.3750, 0.3871, 0.4138, 0.4286, 0.4444, 0.4615, 0.4800, 0.5000,\n","           0.5217, 0.5455, 0.5714, 0.6000, 0.6316, 0.6667, 0.7059, 0.7500, 0.8000,\n","           0.8571, 0.9231, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n","   tensor([0.0474, 0.0476, 0.0478, 0.0480, 0.0481, 0.0483, 0.0485, 0.0487, 0.0489,\n","           0.0492, 0.0494, 0.0496, 0.0498, 0.0502, 0.0504, 0.0506, 0.0508, 0.0510,\n","           0.0512, 0.0514, 0.0516, 0.0518, 0.0520, 0.0522, 0.0524, 0.0526, 0.0528,\n","           0.0531, 0.0533, 0.0535, 0.0537, 0.0539, 0.0542, 0.0544, 0.0546, 0.0549,\n","           0.0551, 0.0553, 0.0558, 0.0560, 0.0563, 0.0565, 0.0568, 0.0570, 0.0573,\n","           0.0575, 0.0578, 0.0580, 0.0583, 0.0586, 0.0588, 0.0591, 0.0594, 0.0596,\n","           0.0599, 0.0602, 0.0605, 0.0607, 0.0610, 0.0613, 0.0616, 0.0619, 0.0622,\n","           0.0625, 0.0628, 0.0634, 0.0637, 0.0640, 0.0644, 0.0647, 0.0650, 0.0653,\n","           0.0657, 0.0660, 0.0663, 0.0667, 0.0670, 0.0674, 0.0677, 0.0681, 0.0684,\n","           0.0688, 0.0691, 0.0695, 0.0699, 0.0703, 0.0707, 0.0710, 0.0714, 0.0718,\n","           0.0722, 0.0726, 0.0734, 0.0739, 0.0743, 0.0747, 0.0756, 0.0760, 0.0765,\n","           0.0769, 0.0774, 0.0778, 0.0783, 0.0788, 0.0793, 0.0798, 0.0802, 0.0807,\n","           0.0812, 0.0818, 0.0823, 0.0828, 0.0833, 0.0839, 0.0844, 0.0850, 0.0855,\n","           0.0861, 0.0867, 0.0872, 0.0878, 0.0884, 0.0890, 0.0897, 0.0903, 0.0909,\n","           0.0915, 0.0922, 0.0929, 0.0935, 0.0942, 0.0949, 0.0956, 0.0963, 0.0970,\n","           0.0977, 0.0985, 0.0992, 0.1000, 0.1008, 0.1016, 0.1024, 0.1032, 0.1040,\n","           0.1048, 0.1057, 0.1066, 0.1074, 0.1083, 0.1092, 0.1102, 0.1111, 0.1121,\n","           0.1130, 0.1140, 0.1150, 0.1161, 0.1081, 0.1091, 0.1101, 0.1111, 0.1121,\n","           0.1132, 0.1154, 0.1165, 0.1176, 0.1188, 0.1200, 0.1212, 0.1224, 0.1237,\n","           0.1250, 0.1263, 0.1277, 0.1290, 0.1304, 0.1319, 0.1333, 0.1348, 0.1364,\n","           0.1379, 0.1395, 0.1412, 0.1429, 0.1446, 0.1463, 0.1481, 0.1500, 0.1519,\n","           0.1538, 0.1558, 0.1579, 0.1600, 0.1622, 0.1644, 0.1667, 0.1690, 0.1714,\n","           0.1739, 0.1765, 0.1791, 0.1818, 0.1846, 0.1875, 0.1905, 0.1935, 0.1967,\n","           0.2000, 0.2034, 0.2069, 0.2105, 0.2143, 0.2182, 0.2222, 0.2264, 0.2308,\n","           0.2353, 0.2400, 0.2449, 0.2500, 0.2553, 0.2609, 0.2667, 0.2727, 0.2791,\n","           0.2857, 0.2927, 0.3000, 0.3077, 0.3158, 0.3243, 0.3333, 0.3429, 0.3529,\n","           0.3636, 0.3750, 0.3871, 0.4000, 0.4138, 0.4286, 0.4444, 0.4615, 0.4800,\n","           0.5000, 0.5217, 0.5455, 0.5714, 0.6000, 0.6316, 0.6667, 0.7059, 0.7500,\n","           0.7333, 0.7857, 0.8462, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n","   tensor([0.6496, 0.6520, 0.6544, 0.6568, 0.6593, 0.6617, 0.6642, 0.6667, 0.6692,\n","           0.6717, 0.6742, 0.6768, 0.6820, 0.6846, 0.6873, 0.6899, 0.6926, 0.6953,\n","           0.6980, 0.7008, 0.7036, 0.7063, 0.7092, 0.7120, 0.7149, 0.7177, 0.7206,\n","           0.7236, 0.7265, 0.7295, 0.7325, 0.7355, 0.7417, 0.7448, 0.7479, 0.7511,\n","           0.7542, 0.7574, 0.7607, 0.7639, 0.7672, 0.7706, 0.7739, 0.7773, 0.7807,\n","           0.7841, 0.7876, 0.7911, 0.7946, 0.7982, 0.8054, 0.8091, 0.8128, 0.8165,\n","           0.8203, 0.8241, 0.8279, 0.8318, 0.8357, 0.8396, 0.8436, 0.8476, 0.8517,\n","           0.8558, 0.8599, 0.8641, 0.8683, 0.8725, 0.8768, 0.8812, 0.8856, 0.8900,\n","           0.8945, 0.8990, 0.9036, 0.9082, 0.9128, 0.9124, 0.9171, 0.9219, 0.9215,\n","           0.9263, 0.9312, 0.9362, 0.9412, 0.9462, 0.9565, 0.9617, 0.9615, 0.9669,\n","           0.9722, 0.9777, 0.9775, 0.9774, 0.9830, 0.9829, 0.9828, 0.9884, 0.9884,\n","           0.9883, 0.9882, 0.9882, 0.9881, 0.9880, 0.9880, 0.9879, 0.9878, 0.9939,\n","           0.9938, 0.9938, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000]),\n","   tensor([0.0766, 0.0769, 0.0772, 0.0775, 0.0781, 0.0784, 0.0787, 0.0789, 0.0792,\n","           0.0798, 0.0802, 0.0805, 0.0808, 0.0811, 0.0814, 0.0817, 0.0820, 0.0824,\n","           0.0827, 0.0830, 0.0833, 0.0837, 0.0840, 0.0843, 0.0847, 0.0850, 0.0854,\n","           0.0857, 0.0861, 0.0864, 0.0868, 0.0871, 0.0875, 0.0879, 0.0882, 0.0886,\n","           0.0890, 0.0894, 0.0897, 0.0901, 0.0905, 0.0909, 0.0913, 0.0917, 0.0921,\n","           0.0925, 0.0929, 0.0933, 0.0938, 0.0942, 0.0946, 0.0950, 0.0955, 0.0959,\n","           0.0968, 0.0972, 0.0977, 0.0981, 0.0986, 0.0991, 0.0995, 0.1000, 0.1005,\n","           0.1010, 0.1014, 0.1019, 0.1024, 0.1029, 0.1034, 0.1040, 0.1045, 0.1050,\n","           0.1055, 0.1061, 0.1066, 0.1071, 0.1077, 0.1082, 0.1088, 0.1094, 0.1099,\n","           0.1105, 0.1111, 0.1117, 0.1123, 0.1129, 0.1135, 0.1141, 0.1148, 0.1154,\n","           0.1160, 0.1167, 0.1173, 0.1180, 0.1186, 0.1193, 0.1207, 0.1214, 0.1221,\n","           0.1228, 0.1235, 0.1243, 0.1250, 0.1257, 0.1265, 0.1273, 0.1220, 0.1227,\n","           0.1235, 0.1242, 0.1250, 0.1258, 0.1266, 0.1274, 0.1282, 0.1290, 0.1299,\n","           0.1307, 0.1316, 0.1325, 0.1333, 0.1342, 0.1351, 0.1361, 0.1370, 0.1379,\n","           0.1389, 0.1399, 0.1408, 0.1418, 0.1429, 0.1439, 0.1449, 0.1460, 0.1471,\n","           0.1481, 0.1493, 0.1504, 0.1515, 0.1527, 0.1538, 0.1550, 0.1562, 0.1575,\n","           0.1587, 0.1600, 0.1613, 0.1626, 0.1639, 0.1653, 0.1667, 0.1681, 0.1695,\n","           0.1709, 0.1724, 0.1739, 0.1754, 0.1770, 0.1786, 0.1802, 0.1818, 0.1835,\n","           0.1852, 0.1869, 0.1887, 0.1905, 0.1942, 0.1961, 0.1980, 0.2020, 0.2041,\n","           0.2083, 0.2105, 0.2128, 0.2151, 0.2174, 0.2198, 0.2222, 0.2247, 0.2273,\n","           0.2299, 0.2326, 0.2353, 0.2381, 0.2410, 0.2439, 0.2469, 0.2500, 0.2532,\n","           0.2564, 0.2597, 0.2632, 0.2667, 0.2703, 0.2740, 0.2778, 0.2817, 0.2857,\n","           0.2899, 0.2941, 0.2985, 0.3030, 0.3077, 0.3125, 0.3175, 0.3226, 0.3279,\n","           0.3333, 0.3390, 0.3448, 0.3509, 0.3571, 0.3636, 0.3704, 0.3774, 0.3846,\n","           0.3922, 0.4000, 0.4082, 0.4167, 0.4255, 0.4348, 0.4444, 0.4545, 0.4651,\n","           0.4762, 0.4878, 0.5000, 0.5128, 0.5263, 0.5405, 0.5556, 0.5714, 0.5882,\n","           0.6061, 0.6250, 0.6452, 0.6667, 0.6897, 0.7143, 0.7407, 0.7692, 0.8000,\n","           0.8333, 0.8696, 0.9091, 0.9524, 0.9500, 0.9474, 0.9444, 0.9412, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n","   tensor([0.1058, 0.1062, 0.1066, 0.1070, 0.1078, 0.1082, 0.1086, 0.1090, 0.1094,\n","           0.1098, 0.1103, 0.1107, 0.1115, 0.1120, 0.1124, 0.1128, 0.1133, 0.1137,\n","           0.1142, 0.1146, 0.1151, 0.1155, 0.1160, 0.1165, 0.1169, 0.1174, 0.1179,\n","           0.1184, 0.1189, 0.1193, 0.1198, 0.1203, 0.1208, 0.1213, 0.1218, 0.1224,\n","           0.1229, 0.1234, 0.1239, 0.1245, 0.1250, 0.1255, 0.1261, 0.1266, 0.1278,\n","           0.1283, 0.1289, 0.1295, 0.1300, 0.1306, 0.1312, 0.1318, 0.1324, 0.1330,\n","           0.1336, 0.1349, 0.1355, 0.1362, 0.1368, 0.1374, 0.1381, 0.1388, 0.1394,\n","           0.1401, 0.1408, 0.1415, 0.1422, 0.1429, 0.1436, 0.1443, 0.1450, 0.1457,\n","           0.1465, 0.1472, 0.1480, 0.1487, 0.1495, 0.1503, 0.1510, 0.1518, 0.1526,\n","           0.1534, 0.1543, 0.1551, 0.1559, 0.1576, 0.1585, 0.1593, 0.1602, 0.1611,\n","           0.1620, 0.1629, 0.1638, 0.1648, 0.1657, 0.1667, 0.1676, 0.1686, 0.1696,\n","           0.1706, 0.1716, 0.1726, 0.1737, 0.1747, 0.1758, 0.1768, 0.1779, 0.1790,\n","           0.1801, 0.1813, 0.1824, 0.1835, 0.1847, 0.1859, 0.1871, 0.1883, 0.1895,\n","           0.1908, 0.1921, 0.1933, 0.1946, 0.1959, 0.1973, 0.1986, 0.2000, 0.2014,\n","           0.2028, 0.2042, 0.2057, 0.2071, 0.2086, 0.2101, 0.2132, 0.2148, 0.2164,\n","           0.2180, 0.2197, 0.2214, 0.2231, 0.2248, 0.2266, 0.2283, 0.2302, 0.2320,\n","           0.2339, 0.2358, 0.2377, 0.2397, 0.2417, 0.2437, 0.2458, 0.2479, 0.2500,\n","           0.2522, 0.2544, 0.2566, 0.2589, 0.2613, 0.2636, 0.2661, 0.2685, 0.2710,\n","           0.2736, 0.2762, 0.2788, 0.2816, 0.2843, 0.2871, 0.2900, 0.2929, 0.2959,\n","           0.2990, 0.3021, 0.3053, 0.3085, 0.3118, 0.3152, 0.3187, 0.3222, 0.3258,\n","           0.3295, 0.3333, 0.3372, 0.3412, 0.3452, 0.3494, 0.3537, 0.3580, 0.3625,\n","           0.3671, 0.3718, 0.3766, 0.3816, 0.3867, 0.3919, 0.3973, 0.4028, 0.4085,\n","           0.4143, 0.4203, 0.4265, 0.4328, 0.4394, 0.4308, 0.4375, 0.4444, 0.4516,\n","           0.4590, 0.4667, 0.4746, 0.4828, 0.4912, 0.5000, 0.5091, 0.5185, 0.5283,\n","           0.5385, 0.5490, 0.5600, 0.5714, 0.5833, 0.5957, 0.5778, 0.5909, 0.6047,\n","           0.6190, 0.6341, 0.6500, 0.6667, 0.6842, 0.7027, 0.7222, 0.7429, 0.7647,\n","           0.7879, 0.8125, 0.8387, 0.8667, 0.8966, 0.8929, 0.9259, 0.9615, 0.9600,\n","           0.9583, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n","   tensor([0.0766, 0.0769, 0.0772, 0.0775, 0.0778, 0.0781, 0.0784, 0.0789, 0.0792,\n","           0.0795, 0.0798, 0.0802, 0.0805, 0.0808, 0.0811, 0.0814, 0.0817, 0.0820,\n","           0.0824, 0.0827, 0.0830, 0.0833, 0.0837, 0.0840, 0.0843, 0.0847, 0.0850,\n","           0.0857, 0.0861, 0.0868, 0.0871, 0.0875, 0.0879, 0.0882, 0.0886, 0.0890,\n","           0.0894, 0.0901, 0.0905, 0.0909, 0.0913, 0.0917, 0.0921, 0.0925, 0.0929,\n","           0.0933, 0.0938, 0.0942, 0.0946, 0.0950, 0.0955, 0.0959, 0.0963, 0.0968,\n","           0.0972, 0.0977, 0.0981, 0.0986, 0.0991, 0.0995, 0.1000, 0.1005, 0.1010,\n","           0.1014, 0.1019, 0.1024, 0.1029, 0.1034, 0.1040, 0.1045, 0.1050, 0.1055,\n","           0.1061, 0.1066, 0.1071, 0.1077, 0.1082, 0.1088, 0.1094, 0.1099, 0.1105,\n","           0.1111, 0.1117, 0.1123, 0.1129, 0.1135, 0.1141, 0.1148, 0.1154, 0.1167,\n","           0.1173, 0.1180, 0.1186, 0.1193, 0.1200, 0.1207, 0.1214, 0.1221, 0.1228,\n","           0.1235, 0.1243, 0.1257, 0.1265, 0.1273, 0.1280, 0.1288, 0.1296, 0.1304,\n","           0.1312, 0.1321, 0.1329, 0.1338, 0.1346, 0.1355, 0.1364, 0.1373, 0.1382,\n","           0.1391, 0.1400, 0.1409, 0.1419, 0.1429, 0.1438, 0.1448, 0.1458, 0.1469,\n","           0.1479, 0.1489, 0.1500, 0.1511, 0.1522, 0.1533, 0.1544, 0.1556, 0.1567,\n","           0.1579, 0.1591, 0.1603, 0.1615, 0.1628, 0.1641, 0.1654, 0.1667, 0.1680,\n","           0.1694, 0.1707, 0.1721, 0.1736, 0.1750, 0.1765, 0.1780, 0.1795, 0.1810,\n","           0.1826, 0.1842, 0.1858, 0.1875, 0.1892, 0.1909, 0.1927, 0.1944, 0.1963,\n","           0.1981, 0.2000, 0.2019, 0.2039, 0.2059, 0.2079, 0.2100, 0.2121, 0.2143,\n","           0.2165, 0.2188, 0.2211, 0.2234, 0.2258, 0.2283, 0.2308, 0.2333, 0.2360,\n","           0.2386, 0.2414, 0.2442, 0.2471, 0.2500, 0.2530, 0.2561, 0.2593, 0.2625,\n","           0.2658, 0.2692, 0.2727, 0.2763, 0.2800, 0.2838, 0.2877, 0.2917, 0.2958,\n","           0.3000, 0.3043, 0.3088, 0.3134, 0.3182, 0.3231, 0.3281, 0.3333, 0.3387,\n","           0.3443, 0.3500, 0.3559, 0.3621, 0.3684, 0.3750, 0.3818, 0.3889, 0.3962,\n","           0.4038, 0.4118, 0.4200, 0.4286, 0.4375, 0.4468, 0.4565, 0.4667, 0.4773,\n","           0.4884, 0.5000, 0.5122, 0.5250, 0.5385, 0.5526, 0.5405, 0.5556, 0.5714,\n","           0.5882, 0.6061, 0.6250, 0.6452, 0.6667, 0.6897, 0.7143, 0.7407, 0.7692,\n","           0.8000, 0.8333, 0.8696, 0.9524, 0.9500, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])],\n","  [tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 0.9167, 0.8333, 0.7500, 0.6667, 0.5833, 0.5000,\n","           0.4167, 0.3333, 0.2500, 0.1667, 0.0833, 0.0000]),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.8462, 0.8462, 0.8462, 0.8462, 0.7692, 0.6923, 0.6154, 0.5385, 0.4615,\n","           0.3846, 0.3077, 0.2308, 0.1538, 0.0769, 0.0000]),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9944, 0.9944, 0.9944, 0.9888,\n","           0.9888, 0.9888, 0.9888, 0.9888, 0.9888, 0.9888, 0.9888, 0.9831, 0.9831,\n","           0.9831, 0.9831, 0.9775, 0.9719, 0.9719, 0.9663, 0.9607, 0.9607, 0.9551,\n","           0.9494, 0.9438, 0.9382, 0.9326, 0.9270, 0.9213, 0.9157, 0.9101, 0.9101,\n","           0.9045, 0.8989, 0.8989, 0.8933, 0.8876, 0.8820, 0.8764, 0.8708, 0.8652,\n","           0.8596, 0.8539, 0.8483, 0.8427, 0.8371, 0.8315, 0.8258, 0.8202, 0.8146,\n","           0.8090, 0.8034, 0.7978, 0.7921, 0.7865, 0.7809, 0.7753, 0.7697, 0.7640,\n","           0.7584, 0.7528, 0.7472, 0.7416, 0.7360, 0.7303, 0.7247, 0.7191, 0.7135,\n","           0.7079, 0.7022, 0.6966, 0.6910, 0.6854, 0.6798, 0.6742, 0.6685, 0.6629,\n","           0.6573, 0.6517, 0.6461, 0.6404, 0.6348, 0.6292, 0.6236, 0.6180, 0.6124,\n","           0.6067, 0.6011, 0.5955, 0.5899, 0.5843, 0.5787, 0.5730, 0.5618, 0.5562,\n","           0.5506, 0.5393, 0.5337, 0.5281, 0.5169, 0.5112, 0.5000, 0.4944, 0.4888,\n","           0.4831, 0.4775, 0.4719, 0.4663, 0.4607, 0.4551, 0.4494, 0.4438, 0.4382,\n","           0.4326, 0.4270, 0.4213, 0.4157, 0.4101, 0.4045, 0.3989, 0.3933, 0.3876,\n","           0.3820, 0.3764, 0.3708, 0.3652, 0.3596, 0.3539, 0.3483, 0.3427, 0.3371,\n","           0.3315, 0.3258, 0.3090, 0.3034, 0.2978, 0.2921, 0.2809, 0.2753, 0.2640,\n","           0.2584, 0.2472, 0.2303, 0.2191, 0.2079, 0.2022, 0.1966, 0.1910, 0.1854,\n","           0.1517, 0.1236, 0.1124, 0.1011, 0.0843, 0.0618, 0.0506, 0.0449, 0.0337,\n","           0.0225, 0.0112, 0.0000]),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9048, 0.8571, 0.8095, 0.7619, 0.7619,\n","           0.7143, 0.6667, 0.6190, 0.5714, 0.5238, 0.4762, 0.4286, 0.3810, 0.3333,\n","           0.2857, 0.1905, 0.1429, 0.0952, 0.0476, 0.0000]),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9655, 0.9655, 0.9655, 0.9655,\n","           0.9655, 0.9655, 0.9655, 0.9655, 0.9655, 0.9655, 0.9655, 0.9655, 0.9655,\n","           0.9655, 0.9655, 0.9655, 0.9655, 0.9655, 0.9655, 0.8966, 0.8966, 0.8966,\n","           0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966,\n","           0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8621, 0.8621, 0.8621, 0.8276,\n","           0.7931, 0.7931, 0.7586, 0.7241, 0.6897, 0.6552, 0.6207, 0.5862, 0.5517,\n","           0.5172, 0.4828, 0.4483, 0.4138, 0.3793, 0.3448, 0.3103, 0.2759, 0.2414,\n","           0.2069, 0.1724, 0.1379, 0.1034, 0.0345, 0.0000]),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9048, 0.9048, 0.8571, 0.8095, 0.7619,\n","           0.7143, 0.6667, 0.6190, 0.5714, 0.4762, 0.4286, 0.3810, 0.3333, 0.2857,\n","           0.2381, 0.1905, 0.1429, 0.0952, 0.0476, 0.0000])],\n","  [tensor([2.5236e-16, 7.9896e-15, 2.2335e-14, 3.2687e-14, 2.5649e-13, 6.3785e-13,\n","           6.3940e-13, 1.0341e-12, 1.6237e-12, 2.7814e-12, 3.6997e-12, 4.9465e-12,\n","           1.1115e-11, 1.1179e-11, 1.2338e-11, 1.5128e-11, 1.6304e-11, 1.7131e-11,\n","           1.9287e-11, 2.7465e-11, 3.1965e-11, 3.3568e-11, 3.4227e-11, 3.5218e-11,\n","           3.5850e-11, 3.7311e-11, 3.9765e-11, 4.2784e-11, 4.7682e-11, 5.0555e-11,\n","           5.0769e-11, 5.1075e-11, 5.5080e-11, 5.9533e-11, 6.1436e-11, 6.5046e-11,\n","           7.9051e-11, 8.5744e-11, 9.2099e-11, 9.3708e-11, 9.5650e-11, 9.6202e-11,\n","           9.8632e-11, 1.0135e-10, 1.0461e-10, 1.0691e-10, 1.2086e-10, 1.2356e-10,\n","           1.2717e-10, 1.3082e-10, 1.3511e-10, 1.3843e-10, 1.4021e-10, 1.4151e-10,\n","           1.4158e-10, 1.4308e-10, 1.4760e-10, 1.5434e-10, 1.5837e-10, 1.6881e-10,\n","           1.8352e-10, 1.9069e-10, 1.9246e-10, 2.0130e-10, 2.0857e-10, 2.1591e-10,\n","           2.2108e-10, 2.2160e-10, 2.2435e-10, 2.4748e-10, 2.5870e-10, 2.6177e-10,\n","           2.8163e-10, 2.8418e-10, 3.1742e-10, 4.1387e-10, 4.1584e-10, 4.1981e-10,\n","           4.6695e-10, 4.7068e-10, 4.7828e-10, 4.8366e-10, 5.2460e-10, 5.2675e-10,\n","           5.6057e-10, 5.9546e-10, 7.5502e-10, 8.2505e-10, 9.2683e-10, 9.3643e-10,\n","           1.1325e-09, 1.3172e-09, 1.4363e-09, 1.4499e-09, 1.5595e-09, 1.8677e-09,\n","           2.1242e-09, 2.4110e-09, 2.4261e-09, 2.5073e-09, 2.5606e-09, 2.6735e-09,\n","           2.6887e-09, 2.9335e-09, 3.2670e-09, 3.5744e-09, 3.8939e-09, 3.9040e-09,\n","           4.4142e-09, 4.8654e-09, 5.0750e-09, 5.4201e-09, 5.8334e-09, 6.3559e-09,\n","           6.9287e-09, 8.0230e-09, 8.0619e-09, 8.1252e-09, 8.9212e-09, 9.2772e-09,\n","           9.6434e-09, 1.1448e-08, 1.2124e-08, 1.2217e-08, 1.2658e-08, 1.3462e-08,\n","           1.4097e-08, 1.4332e-08, 1.4968e-08, 1.5513e-08, 1.6181e-08, 2.0559e-08,\n","           2.1311e-08, 2.1581e-08, 2.1780e-08, 2.2230e-08, 2.6313e-08, 2.7617e-08,\n","           2.9365e-08, 3.4275e-08, 3.9079e-08, 3.9132e-08, 3.9370e-08, 4.2070e-08,\n","           4.3781e-08, 5.6921e-08, 5.9986e-08, 6.0435e-08, 6.1633e-08, 6.5100e-08,\n","           6.7946e-08, 7.3339e-08, 7.6565e-08, 7.7310e-08, 8.1004e-08, 8.4379e-08,\n","           8.9406e-08, 9.3194e-08, 9.7235e-08, 1.0509e-07, 1.0581e-07, 1.1362e-07,\n","           1.1440e-07, 1.2072e-07, 1.2312e-07, 1.3264e-07, 1.5826e-07, 1.6918e-07,\n","           1.7674e-07, 2.0000e-07, 2.5907e-07, 2.6883e-07, 2.7760e-07, 2.7950e-07,\n","           2.8179e-07, 2.9172e-07, 3.2229e-07, 3.5455e-07, 4.0381e-07, 4.8047e-07,\n","           5.2951e-07, 5.3564e-07, 5.5655e-07, 5.5810e-07, 5.6284e-07, 5.7238e-07,\n","           6.1935e-07, 7.1409e-07, 7.4233e-07, 7.8038e-07, 8.4848e-07, 1.0262e-06,\n","           1.0475e-06, 1.2196e-06, 1.2448e-06, 1.4256e-06, 1.9544e-06, 1.9788e-06,\n","           2.0201e-06, 2.0266e-06, 2.5101e-06, 2.8889e-06, 3.0909e-06, 3.4101e-06,\n","           3.7176e-06, 4.2154e-06, 4.4422e-06, 5.0637e-06, 5.8318e-06, 5.9396e-06,\n","           6.1376e-06, 6.7439e-06, 7.0413e-06, 9.0440e-06, 1.0598e-05, 1.4641e-05,\n","           1.6486e-05, 1.7187e-05, 1.7828e-05, 1.8890e-05, 2.3208e-05, 2.3476e-05,\n","           2.7761e-05, 3.1505e-05, 4.2020e-05, 4.4740e-05, 4.6474e-05, 5.2174e-05,\n","           6.3712e-05, 8.0593e-05, 8.3176e-05, 8.5389e-05, 1.2283e-04, 1.6677e-04,\n","           1.8531e-04, 2.4032e-04, 2.9167e-04, 3.6462e-04, 3.9335e-04, 4.0294e-04,\n","           4.3587e-04, 5.2579e-04, 6.8195e-04, 8.2843e-04, 1.1430e-03, 1.2276e-03,\n","           2.8034e-03, 5.5881e-03, 1.3249e-02, 1.3762e-02, 1.5673e-02, 1.6763e-02,\n","           6.7399e-02, 3.1152e-01, 8.4221e-01, 9.9520e-01, 9.9707e-01, 9.9818e-01,\n","           9.9909e-01, 9.9963e-01, 9.9967e-01, 9.9982e-01, 9.9994e-01, 9.9995e-01,\n","           9.9997e-01, 9.9999e-01]),\n","   tensor([6.9692e-16, 6.2608e-13, 4.3382e-12, 1.6762e-11, 1.8608e-11, 2.1213e-11,\n","           4.1765e-11, 4.4013e-11, 4.7200e-11, 5.7903e-11, 7.7218e-11, 1.0175e-10,\n","           1.0966e-10, 1.1172e-10, 1.2685e-10, 1.4849e-10, 1.6201e-10, 1.8617e-10,\n","           2.0259e-10, 2.3068e-10, 2.9960e-10, 3.0493e-10, 3.8994e-10, 4.9029e-10,\n","           5.4040e-10, 5.4124e-10, 5.9544e-10, 6.2357e-10, 8.0369e-10, 8.8355e-10,\n","           9.2453e-10, 9.8860e-10, 1.0123e-09, 1.1574e-09, 1.1946e-09, 1.2778e-09,\n","           1.8180e-09, 1.8277e-09, 3.0777e-09, 3.6215e-09, 4.0258e-09, 4.1468e-09,\n","           4.5473e-09, 4.6215e-09, 5.4620e-09, 5.8255e-09, 6.7837e-09, 7.9123e-09,\n","           8.2291e-09, 8.6216e-09, 8.8111e-09, 1.0907e-08, 1.1314e-08, 1.4091e-08,\n","           1.6843e-08, 1.9051e-08, 1.9430e-08, 2.1396e-08, 2.8488e-08, 3.2241e-08,\n","           3.4181e-08, 3.5715e-08, 3.7231e-08, 3.8916e-08, 4.3265e-08, 4.3820e-08,\n","           4.5454e-08, 5.0067e-08, 5.4303e-08, 6.2577e-08, 7.4593e-08, 7.7146e-08,\n","           8.4377e-08, 8.6630e-08, 8.9050e-08, 8.9754e-08, 8.9897e-08, 9.3397e-08,\n","           1.0001e-07, 1.0338e-07, 1.0602e-07, 1.1645e-07, 1.2377e-07, 1.2460e-07,\n","           1.2934e-07, 1.2972e-07, 1.3534e-07, 1.3542e-07, 1.3697e-07, 1.4556e-07,\n","           1.4819e-07, 1.5020e-07, 1.5512e-07, 1.5974e-07, 1.6331e-07, 1.6337e-07,\n","           1.7037e-07, 1.8159e-07, 1.8960e-07, 1.9256e-07, 2.0335e-07, 2.0786e-07,\n","           2.1122e-07, 2.1421e-07, 2.3857e-07, 2.3926e-07, 2.6589e-07, 2.6893e-07,\n","           2.7003e-07, 2.7776e-07, 2.9165e-07, 2.9901e-07, 3.0472e-07, 3.0652e-07,\n","           3.1451e-07, 3.1871e-07, 3.2424e-07, 3.2893e-07, 3.3328e-07, 3.3770e-07,\n","           3.4706e-07, 3.5689e-07, 3.7438e-07, 3.7741e-07, 3.7771e-07, 3.8283e-07,\n","           3.9361e-07, 4.0869e-07, 4.1748e-07, 4.3350e-07, 4.4452e-07, 4.4935e-07,\n","           4.6338e-07, 4.8713e-07, 5.0050e-07, 5.3341e-07, 5.4015e-07, 5.5490e-07,\n","           5.6853e-07, 5.9564e-07, 6.1135e-07, 6.3355e-07, 6.3440e-07, 7.5524e-07,\n","           7.6732e-07, 7.7990e-07, 7.8837e-07, 8.1863e-07, 8.6518e-07, 8.6941e-07,\n","           8.9694e-07, 9.0620e-07, 1.0237e-06, 1.0359e-06, 1.1349e-06, 1.1931e-06,\n","           1.2021e-06, 1.3149e-06, 1.4033e-06, 1.4808e-06, 1.5747e-06, 1.6614e-06,\n","           1.7191e-06, 1.7761e-06, 1.9806e-06, 2.0654e-06, 2.0706e-06, 2.1534e-06,\n","           2.2563e-06, 2.4077e-06, 2.5044e-06, 2.5263e-06, 2.5915e-06, 2.7712e-06,\n","           2.8052e-06, 2.8175e-06, 2.9184e-06, 3.6076e-06, 3.7302e-06, 3.9662e-06,\n","           3.9884e-06, 4.1693e-06, 4.2913e-06, 5.1154e-06, 5.2075e-06, 5.4023e-06,\n","           5.4779e-06, 6.3511e-06, 6.9775e-06, 7.0553e-06, 7.7951e-06, 8.3699e-06,\n","           8.8719e-06, 9.0947e-06, 9.6958e-06, 1.0364e-05, 1.1648e-05, 1.1717e-05,\n","           1.1754e-05, 1.2090e-05, 1.2421e-05, 1.2702e-05, 1.2952e-05, 1.3294e-05,\n","           1.4625e-05, 1.5935e-05, 1.6748e-05, 1.6955e-05, 1.6959e-05, 1.8793e-05,\n","           2.0009e-05, 2.0034e-05, 2.0512e-05, 2.0742e-05, 2.1788e-05, 2.1871e-05,\n","           2.2454e-05, 3.2002e-05, 3.5358e-05, 3.6831e-05, 4.4327e-05, 4.4387e-05,\n","           5.2010e-05, 5.2966e-05, 5.5074e-05, 5.8111e-05, 8.1216e-05, 9.9530e-05,\n","           9.9934e-05, 1.0650e-04, 1.3736e-04, 1.3940e-04, 2.1220e-04, 2.2992e-04,\n","           2.6440e-04, 2.8441e-04, 2.9007e-04, 3.2648e-04, 3.6963e-04, 3.7667e-04,\n","           4.1313e-04, 4.4089e-04, 4.7670e-04, 7.0742e-04, 7.0982e-04, 7.3563e-04,\n","           8.1561e-04, 9.4306e-04, 1.4506e-03, 3.2353e-03, 9.3515e-03, 1.4759e-02,\n","           2.9239e-02, 3.3101e-01, 3.3568e-01, 9.7960e-01, 9.8620e-01, 9.9985e-01,\n","           9.9992e-01, 9.9994e-01, 9.9995e-01, 9.9996e-01, 9.9996e-01, 1.0000e+00,\n","           1.0000e+00, 1.0000e+00]),\n","   tensor([1.3256e-09, 2.6407e-09, 3.1382e-09, 3.3726e-09, 1.0128e-08, 1.5816e-08,\n","           2.0068e-08, 3.1688e-08, 3.5788e-08, 5.2204e-08, 7.5000e-08, 9.1003e-08,\n","           1.2877e-07, 1.4012e-07, 1.6643e-07, 2.0710e-07, 3.9230e-07, 4.5919e-07,\n","           9.8842e-07, 1.0164e-06, 1.0865e-06, 1.1636e-06, 2.1968e-06, 2.8576e-06,\n","           2.8797e-06, 3.0036e-06, 3.1773e-06, 4.1014e-06, 5.5906e-06, 8.5762e-06,\n","           1.1134e-05, 1.2389e-05, 1.8028e-05, 1.8592e-05, 2.0706e-05, 2.3117e-05,\n","           2.9848e-05, 3.1929e-05, 3.4522e-05, 3.6561e-05, 3.7809e-05, 3.9439e-05,\n","           4.3704e-05, 4.6482e-05, 4.8165e-05, 5.5336e-05, 9.5983e-05, 1.1858e-04,\n","           1.2171e-04, 1.3323e-04, 1.3351e-04, 1.8391e-04, 1.9330e-04, 2.1635e-04,\n","           2.1933e-04, 2.4563e-04, 2.4979e-04, 2.6470e-04, 3.2189e-04, 3.3151e-04,\n","           4.0368e-04, 4.8196e-04, 7.3511e-04, 7.6718e-04, 8.4533e-04, 9.0533e-04,\n","           1.0626e-03, 1.5032e-03, 1.6514e-03, 2.1510e-03, 2.4762e-03, 3.3735e-03,\n","           3.4362e-03, 4.8272e-03, 5.5874e-03, 8.5493e-03, 9.2294e-03, 1.9893e-02,\n","           2.7292e-02, 3.2436e-02, 3.5555e-02, 4.2129e-02, 6.1168e-02, 6.1859e-02,\n","           8.7200e-02, 9.6874e-02, 1.3956e-01, 1.4666e-01, 1.6053e-01, 1.6507e-01,\n","           1.7852e-01, 2.6081e-01, 2.6932e-01, 3.9252e-01, 4.0720e-01, 4.2405e-01,\n","           6.6375e-01, 6.7832e-01, 7.6392e-01, 8.5628e-01, 8.9697e-01, 9.0806e-01,\n","           9.5480e-01, 9.5569e-01, 9.5725e-01, 9.6232e-01, 9.6475e-01, 9.6699e-01,\n","           9.6796e-01, 9.7076e-01, 9.8245e-01, 9.8380e-01, 9.8422e-01, 9.8759e-01,\n","           9.8852e-01, 9.8955e-01, 9.8981e-01, 9.9056e-01, 9.9106e-01, 9.9201e-01,\n","           9.9303e-01, 9.9324e-01, 9.9402e-01, 9.9408e-01, 9.9426e-01, 9.9557e-01,\n","           9.9694e-01, 9.9707e-01, 9.9731e-01, 9.9750e-01, 9.9763e-01, 9.9783e-01,\n","           9.9825e-01, 9.9832e-01, 9.9835e-01, 9.9838e-01, 9.9846e-01, 9.9852e-01,\n","           9.9880e-01, 9.9885e-01, 9.9886e-01, 9.9897e-01, 9.9907e-01, 9.9948e-01,\n","           9.9948e-01, 9.9949e-01, 9.9959e-01, 9.9960e-01, 9.9966e-01, 9.9969e-01,\n","           9.9970e-01, 9.9970e-01, 9.9972e-01, 9.9975e-01, 9.9978e-01, 9.9978e-01,\n","           9.9981e-01, 9.9984e-01, 9.9986e-01, 9.9988e-01, 9.9988e-01, 9.9989e-01,\n","           9.9990e-01, 9.9993e-01, 9.9993e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n","           9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n","           9.9996e-01, 9.9996e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n","           9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n","           9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9999e-01, 9.9999e-01,\n","           9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n","           9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n","           9.9999e-01, 9.9999e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n","           1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n","           1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n","           1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n","           1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n","           1.0000e+00, 1.0000e+00]),\n","   tensor([7.3482e-11, 9.7111e-11, 4.7503e-10, 1.5006e-09, 1.9710e-09, 2.0367e-09,\n","           2.9146e-09, 3.5578e-09, 3.5872e-09, 4.8091e-09, 4.9241e-09, 5.4332e-09,\n","           5.6796e-09, 5.7677e-09, 6.2420e-09, 6.2965e-09, 6.8784e-09, 6.9570e-09,\n","           7.0828e-09, 7.5857e-09, 7.7401e-09, 8.1904e-09, 8.4623e-09, 8.6867e-09,\n","           9.1624e-09, 9.1758e-09, 9.6970e-09, 9.8485e-09, 9.9985e-09, 1.0652e-08,\n","           1.0965e-08, 1.2146e-08, 1.2538e-08, 1.2669e-08, 1.3220e-08, 1.3221e-08,\n","           1.3529e-08, 1.3953e-08, 1.4004e-08, 1.4106e-08, 1.4305e-08, 1.4464e-08,\n","           1.4774e-08, 1.5041e-08, 1.6170e-08, 1.6435e-08, 2.1293e-08, 2.4205e-08,\n","           2.5642e-08, 2.7273e-08, 2.8518e-08, 2.9054e-08, 2.9801e-08, 4.3692e-08,\n","           4.4057e-08, 4.4821e-08, 5.6222e-08, 5.8182e-08, 6.0913e-08, 6.4663e-08,\n","           6.6403e-08, 6.7726e-08, 7.2219e-08, 7.6095e-08, 7.6449e-08, 7.9067e-08,\n","           9.3704e-08, 9.9300e-08, 1.0339e-07, 1.0535e-07, 1.0547e-07, 1.1995e-07,\n","           1.2849e-07, 1.4709e-07, 1.4950e-07, 1.5782e-07, 1.6819e-07, 1.7928e-07,\n","           1.8801e-07, 2.0040e-07, 2.1928e-07, 2.2128e-07, 2.3151e-07, 2.4157e-07,\n","           2.4225e-07, 2.6192e-07, 2.7190e-07, 2.8793e-07, 2.9532e-07, 2.9780e-07,\n","           3.0172e-07, 3.3362e-07, 3.6349e-07, 3.7172e-07, 3.7210e-07, 3.7425e-07,\n","           4.1182e-07, 4.2212e-07, 4.4535e-07, 4.5046e-07, 4.5713e-07, 5.1469e-07,\n","           5.3507e-07, 6.5310e-07, 7.1273e-07, 7.3322e-07, 7.4042e-07, 8.2538e-07,\n","           8.4628e-07, 8.7950e-07, 8.8737e-07, 8.9911e-07, 9.6807e-07, 1.0250e-06,\n","           1.1258e-06, 1.1602e-06, 1.1632e-06, 1.2652e-06, 1.3358e-06, 1.4305e-06,\n","           1.4838e-06, 1.5425e-06, 1.5851e-06, 1.5926e-06, 1.6095e-06, 1.6619e-06,\n","           1.7653e-06, 1.8139e-06, 1.9583e-06, 2.2396e-06, 2.3810e-06, 2.5220e-06,\n","           2.5795e-06, 2.8633e-06, 3.1125e-06, 3.1664e-06, 3.4475e-06, 3.4963e-06,\n","           3.7453e-06, 4.0968e-06, 4.5116e-06, 4.6404e-06, 5.4132e-06, 5.6381e-06,\n","           6.1152e-06, 6.5701e-06, 7.0155e-06, 7.7937e-06, 7.9965e-06, 8.5620e-06,\n","           8.6028e-06, 9.2948e-06, 1.1044e-05, 1.1090e-05, 1.1899e-05, 1.2457e-05,\n","           1.3325e-05, 1.3553e-05, 1.7048e-05, 1.7242e-05, 1.7537e-05, 2.1335e-05,\n","           2.3201e-05, 2.6086e-05, 2.6642e-05, 2.7567e-05, 2.9412e-05, 3.1117e-05,\n","           3.2901e-05, 3.8534e-05, 3.9309e-05, 4.0949e-05, 4.1593e-05, 4.1916e-05,\n","           4.2713e-05, 4.6754e-05, 4.9815e-05, 5.1580e-05, 5.9979e-05, 6.3853e-05,\n","           6.4783e-05, 7.5225e-05, 7.8568e-05, 7.9041e-05, 8.2699e-05, 9.3010e-05,\n","           1.0134e-04, 1.0702e-04, 1.1548e-04, 1.2417e-04, 1.2462e-04, 1.2951e-04,\n","           1.3330e-04, 1.3614e-04, 1.6399e-04, 1.6499e-04, 1.7121e-04, 1.7756e-04,\n","           1.8693e-04, 1.8943e-04, 1.9477e-04, 2.0837e-04, 2.1774e-04, 2.4238e-04,\n","           2.8362e-04, 2.9754e-04, 3.0663e-04, 3.4105e-04, 3.5710e-04, 3.7300e-04,\n","           4.6314e-04, 6.0123e-04, 7.6099e-04, 8.0219e-04, 8.2108e-04, 8.8410e-04,\n","           9.1453e-04, 9.4860e-04, 1.4201e-03, 1.4599e-03, 1.4710e-03, 1.4836e-03,\n","           1.7870e-03, 2.1021e-03, 2.2148e-03, 2.5130e-03, 2.6834e-03, 3.6584e-03,\n","           4.4278e-03, 6.0101e-03, 6.0875e-03, 6.3837e-03, 7.5888e-03, 8.7740e-03,\n","           1.1483e-02, 1.5793e-02, 1.8217e-02, 2.5739e-02, 5.4550e-02, 7.0848e-02,\n","           8.7489e-02, 1.0303e-01, 1.2682e-01, 1.8988e-01, 4.4936e-01, 4.9399e-01,\n","           8.3430e-01, 9.1262e-01, 9.2911e-01, 9.3852e-01, 9.6729e-01, 9.9474e-01,\n","           9.9533e-01, 9.9906e-01, 9.9915e-01, 9.9937e-01, 9.9950e-01, 9.9969e-01,\n","           9.9973e-01, 9.9973e-01, 9.9978e-01, 9.9987e-01, 9.9992e-01, 9.9994e-01,\n","           9.9996e-01, 9.9999e-01]),\n","   tensor([1.6322e-12, 1.8544e-12, 4.1977e-12, 1.0980e-11, 1.9625e-11, 2.2830e-11,\n","           4.9419e-11, 8.0385e-11, 8.5503e-11, 9.5538e-11, 1.6239e-10, 2.2694e-10,\n","           2.4448e-10, 3.7550e-10, 9.5173e-10, 1.0134e-09, 1.0917e-09, 1.1199e-09,\n","           1.4519e-09, 1.5623e-09, 1.5906e-09, 1.6373e-09, 1.9013e-09, 3.1175e-09,\n","           4.5165e-09, 5.4184e-09, 6.9215e-09, 7.8179e-09, 8.4272e-09, 9.0385e-09,\n","           9.7497e-09, 1.0344e-08, 1.0786e-08, 1.1426e-08, 1.7128e-08, 1.8887e-08,\n","           1.9704e-08, 2.0567e-08, 2.3351e-08, 2.4639e-08, 2.4699e-08, 2.4940e-08,\n","           2.5319e-08, 3.2085e-08, 3.2935e-08, 3.5760e-08, 3.7404e-08, 3.8617e-08,\n","           3.9213e-08, 4.8361e-08, 5.0357e-08, 5.3534e-08, 5.8680e-08, 6.0256e-08,\n","           6.2383e-08, 6.4205e-08, 8.6885e-08, 9.8661e-08, 1.0171e-07, 1.0924e-07,\n","           1.1478e-07, 1.1561e-07, 1.2171e-07, 1.3557e-07, 1.5785e-07, 1.7303e-07,\n","           1.8791e-07, 1.9772e-07, 2.1692e-07, 2.3624e-07, 2.4568e-07, 2.4580e-07,\n","           2.7432e-07, 2.9795e-07, 3.3402e-07, 3.4052e-07, 3.4144e-07, 3.4741e-07,\n","           3.7728e-07, 3.9978e-07, 4.0219e-07, 4.3262e-07, 4.4926e-07, 4.5450e-07,\n","           4.7169e-07, 5.5210e-07, 5.6501e-07, 5.7036e-07, 6.6219e-07, 7.2143e-07,\n","           7.3657e-07, 8.3972e-07, 8.4176e-07, 9.2074e-07, 9.4481e-07, 9.9943e-07,\n","           1.0247e-06, 1.0307e-06, 1.0428e-06, 1.0481e-06, 1.0768e-06, 1.1233e-06,\n","           1.1632e-06, 1.2403e-06, 1.3308e-06, 1.3361e-06, 1.3480e-06, 1.3980e-06,\n","           1.4529e-06, 1.5109e-06, 1.5564e-06, 1.6151e-06, 1.6200e-06, 1.6445e-06,\n","           1.6764e-06, 1.7168e-06, 1.7649e-06, 1.8212e-06, 1.8546e-06, 1.8612e-06,\n","           1.8738e-06, 1.8746e-06, 1.9003e-06, 1.9031e-06, 1.9226e-06, 1.9279e-06,\n","           1.9606e-06, 1.9994e-06, 2.0978e-06, 2.1259e-06, 2.1568e-06, 2.1686e-06,\n","           2.2139e-06, 2.3209e-06, 2.3322e-06, 2.4330e-06, 2.5946e-06, 2.7328e-06,\n","           3.2941e-06, 3.2975e-06, 3.3380e-06, 3.3617e-06, 4.0799e-06, 4.1497e-06,\n","           4.7973e-06, 4.8187e-06, 4.8708e-06, 4.9700e-06, 5.1210e-06, 5.6117e-06,\n","           5.8879e-06, 6.8701e-06, 7.0228e-06, 7.7631e-06, 7.8032e-06, 8.2764e-06,\n","           8.6944e-06, 9.2247e-06, 9.9745e-06, 1.0244e-05, 1.0292e-05, 1.0310e-05,\n","           1.2494e-05, 1.2577e-05, 1.2601e-05, 1.3424e-05, 1.5175e-05, 1.6988e-05,\n","           1.8409e-05, 2.1249e-05, 2.1329e-05, 2.2869e-05, 2.5199e-05, 2.8715e-05,\n","           3.0665e-05, 3.1434e-05, 3.2369e-05, 3.3053e-05, 3.3805e-05, 3.3897e-05,\n","           3.7060e-05, 4.4577e-05, 4.6091e-05, 4.6384e-05, 4.6878e-05, 5.6346e-05,\n","           6.1664e-05, 6.1797e-05, 6.5498e-05, 7.7376e-05, 8.6104e-05, 9.1504e-05,\n","           9.9015e-05, 9.9303e-05, 1.0586e-04, 1.0853e-04, 1.1001e-04, 1.2075e-04,\n","           1.2679e-04, 1.3736e-04, 1.5435e-04, 1.5894e-04, 1.5921e-04, 2.1596e-04,\n","           2.2471e-04, 2.4038e-04, 2.5389e-04, 2.6747e-04, 2.7286e-04, 2.8240e-04,\n","           3.0340e-04, 3.7188e-04, 4.4050e-04, 4.9652e-04, 5.8417e-04, 6.3953e-04,\n","           6.9143e-04, 7.9547e-04, 9.6087e-04, 1.4438e-03, 1.7345e-03, 2.0335e-03,\n","           4.8137e-03, 5.5645e-03, 5.8105e-03, 6.9851e-03, 7.9827e-03, 1.0256e-02,\n","           1.1370e-02, 1.4826e-02, 2.7854e-02, 3.6222e-02, 4.0050e-02, 4.5179e-02,\n","           9.1928e-02, 2.3529e-01, 3.1961e-01, 5.9219e-01, 7.1593e-01, 7.3826e-01,\n","           7.6677e-01, 7.7078e-01, 8.3189e-01, 8.4067e-01, 8.8843e-01, 9.6619e-01,\n","           9.9426e-01, 9.9508e-01, 9.9785e-01, 9.9902e-01, 9.9967e-01, 9.9969e-01,\n","           9.9979e-01, 9.9983e-01, 9.9997e-01, 9.9998e-01, 9.9999e-01, 9.9999e-01,\n","           1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n","           1.0000e+00, 1.0000e+00]),\n","   tensor([6.4652e-14, 1.2442e-11, 2.4197e-11, 3.3645e-11, 6.6679e-11, 8.7716e-11,\n","           9.8079e-11, 1.1337e-10, 1.2483e-10, 1.3196e-10, 2.0882e-10, 2.1893e-10,\n","           2.2510e-10, 2.5300e-10, 3.0766e-10, 3.2192e-10, 4.5486e-10, 4.8098e-10,\n","           7.5039e-10, 7.6430e-10, 8.4429e-10, 1.0732e-09, 1.7051e-09, 1.7708e-09,\n","           1.8602e-09, 2.1112e-09, 2.3180e-09, 2.5573e-09, 2.8544e-09, 3.3377e-09,\n","           4.1517e-09, 4.4541e-09, 4.5950e-09, 4.9043e-09, 5.4043e-09, 6.0666e-09,\n","           6.2787e-09, 6.3079e-09, 6.3650e-09, 6.4817e-09, 6.6650e-09, 6.7742e-09,\n","           6.9231e-09, 7.0119e-09, 7.3996e-09, 7.9965e-09, 8.4235e-09, 8.4867e-09,\n","           8.5090e-09, 8.5898e-09, 8.8289e-09, 9.2751e-09, 9.3466e-09, 9.7434e-09,\n","           9.7711e-09, 1.0073e-08, 1.0380e-08, 1.1495e-08, 1.1688e-08, 1.2334e-08,\n","           1.2373e-08, 1.2629e-08, 1.2995e-08, 1.3113e-08, 1.3493e-08, 1.4298e-08,\n","           1.5141e-08, 1.5377e-08, 1.6111e-08, 1.7332e-08, 1.7619e-08, 1.7791e-08,\n","           1.9311e-08, 1.9526e-08, 1.9719e-08, 1.9731e-08, 2.3739e-08, 2.7540e-08,\n","           2.9302e-08, 2.9914e-08, 3.0224e-08, 3.2038e-08, 3.2354e-08, 3.3580e-08,\n","           3.4086e-08, 3.5114e-08, 4.3361e-08, 4.8771e-08, 5.1188e-08, 5.4603e-08,\n","           5.7553e-08, 6.2427e-08, 6.5782e-08, 6.7265e-08, 7.2226e-08, 8.0499e-08,\n","           8.2593e-08, 8.3336e-08, 9.2754e-08, 9.5399e-08, 1.0364e-07, 1.0822e-07,\n","           1.1025e-07, 1.1167e-07, 1.1603e-07, 1.1889e-07, 1.2024e-07, 1.2865e-07,\n","           1.3156e-07, 1.3634e-07, 1.3805e-07, 1.4440e-07, 1.6395e-07, 1.8210e-07,\n","           1.8308e-07, 1.9289e-07, 2.1167e-07, 2.1418e-07, 2.4973e-07, 2.5962e-07,\n","           2.9341e-07, 3.1329e-07, 3.1449e-07, 3.2431e-07, 3.4425e-07, 3.5454e-07,\n","           4.4586e-07, 4.6895e-07, 5.2933e-07, 5.5143e-07, 5.5264e-07, 5.5316e-07,\n","           5.8397e-07, 7.0559e-07, 7.1039e-07, 8.1501e-07, 8.3216e-07, 8.8409e-07,\n","           8.9536e-07, 1.0604e-06, 1.0740e-06, 1.1009e-06, 1.1614e-06, 1.1635e-06,\n","           1.1808e-06, 1.2148e-06, 1.2167e-06, 1.2711e-06, 1.3035e-06, 1.4835e-06,\n","           1.4920e-06, 1.6047e-06, 1.6992e-06, 1.7331e-06, 1.8010e-06, 1.8470e-06,\n","           1.9286e-06, 1.9707e-06, 2.8079e-06, 3.3064e-06, 3.6450e-06, 4.3199e-06,\n","           4.5124e-06, 4.8417e-06, 5.2778e-06, 5.8485e-06, 5.9406e-06, 6.4825e-06,\n","           6.5010e-06, 6.7261e-06, 6.8675e-06, 7.1448e-06, 7.6666e-06, 8.3994e-06,\n","           8.9676e-06, 1.0243e-05, 1.0707e-05, 1.1240e-05, 1.1471e-05, 1.2319e-05,\n","           1.4802e-05, 1.6898e-05, 2.0513e-05, 2.0893e-05, 2.1442e-05, 2.9159e-05,\n","           2.9807e-05, 3.0715e-05, 3.3776e-05, 3.4222e-05, 4.0153e-05, 4.1793e-05,\n","           4.2026e-05, 4.2321e-05, 4.5084e-05, 4.5725e-05, 7.2413e-05, 8.4442e-05,\n","           8.4998e-05, 8.7155e-05, 8.8317e-05, 9.3609e-05, 1.2233e-04, 1.3647e-04,\n","           1.4230e-04, 1.4880e-04, 1.6169e-04, 1.7022e-04, 1.7914e-04, 1.8454e-04,\n","           2.7572e-04, 3.1049e-04, 3.3347e-04, 3.4951e-04, 3.5743e-04, 3.5826e-04,\n","           1.0362e-03, 1.2154e-03, 1.4106e-03, 1.6003e-03, 1.6279e-03, 1.6424e-03,\n","           1.6678e-03, 1.7482e-03, 1.9095e-03, 2.4127e-03, 3.0059e-03, 3.5197e-03,\n","           4.1286e-03, 4.2938e-03, 5.0927e-03, 6.8109e-03, 7.7954e-03, 1.0793e-02,\n","           1.2573e-02, 1.8033e-02, 1.8804e-02, 3.0502e-02, 3.2041e-02, 3.7026e-02,\n","           6.4588e-02, 6.9130e-02, 8.1237e-02, 1.5208e-01, 4.1887e-01, 5.6509e-01,\n","           9.3437e-01, 9.3564e-01, 9.9138e-01, 9.9661e-01, 9.9832e-01, 9.9886e-01,\n","           9.9891e-01, 9.9939e-01, 9.9986e-01, 9.9991e-01, 9.9992e-01, 9.9995e-01,\n","           9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 1.0000e+00,\n","           1.0000e+00, 1.0000e+00])])}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["baseline_model = BaselineLSTM().to(device)\n","baseline_model.load_state_dict(torch.load('baselineLSTM_0122.pth'))\n","baseline_model.half()\n","weights = torch.Tensor([20,20,1,10,10,10]).to(device)\n","#weights = torch.Tensor([1,1,1,1,1,1]).to(device)\n","loss_fn = nn.NLLLoss(weight=weights)\n","print_size_of_model(baseline_model)\n","model_evaluate(baseline_model)"],"metadata":{"id":"wJdYQOZLBSgj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["baseline_model = BaselineLSTM().to(device)\n","print_size_of_model(baseline_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-YXHOpkGsK11","executionInfo":{"status":"ok","timestamp":1705906398262,"user_tz":0,"elapsed":286,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"16e5d0de-f149-4b5e-e6f6-72a6ae6016a7"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Size (MB): 39.539514\n"]}]},{"cell_type":"code","source":["torch.manual_seed(50)\n","baseline_model = BaselineLSTM().to(device)\n","weights = torch.Tensor([20,20,1,10,10,10]).to(device)\n","#weights = torch.Tensor([1,1,1,1,1,1]).to(device)\n","loss_fn = nn.NLLLoss(weight=weights)\n","optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n","history = train(baseline_model, 100, loss_fn, optimizer)"],"metadata":{"id":"rhl6tQV0Pdp2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","baseline_model = BaselineLSTM().to(device)\n","baseline_model.load_state_dict(torch.load('baselineLSTM_0122.pth'))\n","with open('baseline_history_0122.pkl', 'rb') as fp:\n","    baseline_history = pickle.load(fp)"],"metadata":{"id":"b1B_um_OWc6e","executionInfo":{"status":"ok","timestamp":1705903712161,"user_tz":0,"elapsed":711,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["result = model_evaluate(baseline_model)\n","print_size_of_model(baseline_model)\n","result"],"metadata":{"id":"z04EUb8zwYIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.ao.quantization import (\n","  get_default_qconfig_mapping,\n","  get_default_qat_qconfig_mapping,\n","  QConfigMapping,\n",")\n","import torch.ao.quantization.quantize_fx as quantize_fx\n","import copy\n","\n","baseline_model = BaselineLSTM().to(device)\n","baseline_model.load_state_dict(torch.load('baselineLSTM_0122.pth'))"],"metadata":{"id":"XOz7KHIeS78G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705911497001,"user_tz":0,"elapsed":443,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"bc6f34bd-5b5d-4ea5-c496-06e3bfda6723"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from torch.ao.quantization.qconfig_mapping import QConfigMapping\n","from torch.ao.quantization.qconfig import QConfig\n","from torch.ao.quantization.observer import MinMaxObserver\n","from torch.ao.quantization.observer import default_observer\n","\n","qconfig_new = QConfig(\n","    activation=MinMaxObserver.with_args(dtype=torch.quint8),\n","    weight=default_observer.with_args(dtype=torch.quint8))\n","qconfig_mapping = QConfigMapping().set_global(qconfig_new)"],"metadata":{"id":"DGKSnwQh8kat","executionInfo":{"status":"ok","timestamp":1705906909779,"user_tz":0,"elapsed":1,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["model_to_quantize = copy.deepcopy(baseline_model)\n","model_to_quantize.eval()\n","qconfig_mapping = QConfigMapping().set_global(torch.ao.quantization.default_dynamic_qconfig)\n","example_inputs = (X_train[:1])\n","model_prepared = quantize_fx.prepare_fx(model_to_quantize, qconfig_mapping, example_inputs)\n","model_quantized = quantize_fx.convert_fx(model_prepared)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UGykDB_kpQoL","executionInfo":{"status":"ok","timestamp":1705911758045,"user_tz":0,"elapsed":1206,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"300949bd-e612-455f-f2c1-d3fce7de0340"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/ao/nn/quantized/reference/modules/rnn.py:320: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(weight_qparams[\"scale\"], dtype=torch.float, device=device))\n","/usr/local/lib/python3.10/dist-packages/torch/ao/nn/quantized/reference/modules/rnn.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(weight_qparams[\"zero_point\"], dtype=torch.int, device=device))\n"]}]},{"cell_type":"code","source":["weights = torch.Tensor([20,20,1,10,10,10]).to(device)\n","#weights = torch.Tensor([1,1,1,1,1,1]).to(device)\n","loss_fn = nn.NLLLoss(weight=weights)\n","result = model_evaluate(model_quantized)\n","print_size_of_model(model_quantized)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_IncJr7qVf6","executionInfo":{"status":"ok","timestamp":1705911774993,"user_tz":0,"elapsed":13752,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"883be7d1-bfe0-4d67-982a-f08d9c2d8d73"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["1.4564025666978624\n","Size (MB): 9.94109\n"]}]},{"cell_type":"code","source":["import copy\n","torch.manual_seed(50)\n","baseline_model = BaselineLSTM().to(device)\n","weights = torch.Tensor([20,20,1,10,10,10]).to(device)\n","#weights = torch.Tensor([1,1,1,1,1,1]).to(device)\n","loss_fn = nn.NLLLoss(weight=weights)\n","optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n","history = train(baseline_model, 50, loss_fn, optimizer)"],"metadata":{"id":"Wzr-EfnDpfTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import copy\n","baseline_model = BaselineLSTM().to(device)\n","baseline_model.load_state_dict(torch.load('baselineLSTM_0122.pth'))\n","model_to_quantize = copy.deepcopy(baseline_model)\n","qconfig_mapping = get_default_qat_qconfig_mapping(\"qnnpack\")\n","model_to_quantize.train()\n","example_inputs = (X_train[:1])\n","model_prepared = quantize_fx.prepare_qat_fx(model_to_quantize, qconfig_mapping, example_inputs)\n","weights = torch.Tensor([20,20,1,10,10,10]).to(device)\n","#weights = torch.Tensor([1,1,1,1,1,1]).to(device)\n","loss_fn = nn.NLLLoss(weight=weights)\n","optimizer = torch.optim.Adam(model_prepared.parameters(), lr=1e-4)\n","history = train(model_prepared, 100, loss_fn, optimizer)\n","model_quantized = quantize_fx.convert_fx(model_prepared)"],"metadata":{"id":"rgesjHju1oOX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["baseline_model = BaselineLSTM().to(device)\n","#baseline_model.load_state_dict(torch.load('baselineLSTM_0122.pth'))\n","model_to_quantize = copy.deepcopy(baseline_model)\n","qconfig_mapping = get_default_qat_qconfig_mapping(\"qnnpack\")\n","model_to_quantize.train()\n","example_inputs = (X_train[:1])\n","model_prepared = quantize_fx.prepare_qat_fx(model_to_quantize, qconfig_mapping, example_inputs)\n","weights = torch.Tensor([20,20,1,10,10,10]).to(device)\n","#weights = torch.Tensor([1,1,1,1,1,1]).to(device)\n","loss_fn = nn.NLLLoss(weight=weights)\n","optimizer = torch.optim.SGD(model_prepared.parameters(), lr = 1e-5)\n","history = train(model_prepared, 100, loss_fn, optimizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rOu7B2HE36NT","executionInfo":{"status":"error","timestamp":1705906247473,"user_tz":0,"elapsed":3875,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"242f9a3b-4735-4f33-fbd2-78c0e02dff1f"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.7889, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7960, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7868, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7882, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8105, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7763, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7796, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8131, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7899, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7692, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7821, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7870, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7984, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8016, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7923, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7924, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8181, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7925, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7922, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7947, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7865, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7935, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8212, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8112, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7945, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7890, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7855, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7708, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7718, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7865, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8172, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8552, device='cuda:0', grad_fn=<NllLossBackward0>)\n","Epoch 0-- Train loss:1.79 accuracy:0.04 precision:0.01 recall:0.16 f1:0.01\n","Epoch 0-- Valid loss:1.80 accuracy:0.04 precision:0.01 recall:0.17 f1:0.01\n","tensor(1.7857, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7960, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7850, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7893, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8123, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7728, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7783, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8075, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7878, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7692, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7810, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7870, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.7921, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-60c5c316099f>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_prepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_prepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-38-b1e4323d590b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m           \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<eval_with_key>.60\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_post_process_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mactivation_post_process_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mactivation_post_process_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_post_process_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlstm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_post_process_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mactivation_post_process_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mgetitem_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mactivation_post_process_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_post_process_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetitem_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mgetitem_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    880\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["baseline_model = BaselineLSTM().to(device)\n","baseline_model.load_state_dict(torch.load('baselineLSTM_0122.pth'))\n","model_to_quantize = copy.deepcopy(baseline_model)\n","model_fused = quantize_fx.fuse_fx(model_to_quantize)\n","weights = torch.Tensor([20,20,1,10,10,10]).to(device)\n","#weights = torch.Tensor([1,1,1,1,1,1]).to(device)\n","loss_fn = nn.NLLLoss(weight=weights)\n","print_size_of_model(model_fused)\n","model_evaluate(model_fused)"],"metadata":{"id":"O2i98Z57pwRz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.lstm1.weight_hh_l0.data.sign"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdjFfS7-YTNb","executionInfo":{"status":"ok","timestamp":1705915344172,"user_tz":0,"elapsed":7,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"c0c2b1fb-6544-4f3f-ce8a-20228bfde1e1"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function Tensor.sign>"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["import torch.nn as nn\n","import numpy\n","from torch.autograd import Variable\n","class BC():\n","    def __init__(self, model):\n","        # count the number of Conv2d and Linear\n","        count_targets = 0\n","        for m in model.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","                count_targets = count_targets + 1\n","            if isinstance(m, nn.LSTM):\n","                count_targets = count_targets + 2\n","\n","        start_range = 0\n","        end_range = count_targets-1\n","        self.bin_range = numpy.linspace(start_range,\n","                end_range, end_range-start_range+1)\\\n","                        .astype('int').tolist()\n","        self.num_of_params = len(self.bin_range)\n","        self.saved_params = []\n","        self.target_params = []\n","        self.target_modules = []\n","        index = -1\n","        for m in model.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","                index = index + 1\n","                if index in self.bin_range:\n","                    tmp = m.weight.data.clone()\n","                    self.saved_params.append(tmp)\n","                    self.target_modules.append(m.weight)\n","            if isinstance(m, nn.LSTM):\n","                index = index + 1\n","                if index in self.bin_range:\n","                    tmp1 = m.weight_ih_l0.data.clone()\n","                    tmp2 = m.weight_hh_l0.data.clone()\n","                    self.saved_params.append(tmp1)\n","                    self.saved_params.append(tmp2)\n","                    self.target_modules.append(m.weight_ih_l0)\n","                    self.target_modules.append(m.weight_hh_l0)\n","\n","    def binarization(self):\n","        self.save_params()\n","        for index in range(self.num_of_params):\n","            self.target_modules[index].data.copy_(self.target_modules[index].data.sign())\n","\n","\n","    def BWN(self): # Binary Weight Network\n","        self.save_params()\n","        for index in range(self.num_of_params):\n","            E=self.target_modules[index].data.abs().mean()\n","            self.target_modules[index].data.copy_(self.target_modules[index].data.sign() *E)\n","\n","\n","    def save_params(self):\n","        for index in range(self.num_of_params):\n","            self.saved_params[index].copy_(self.target_modules[index].data)\n","\n","\n","    def restore(self):\n","        for index in range(self.num_of_params):\n","            self.target_modules[index].data.copy_(self.saved_params[index])\n","\n","    def clip(self):\n","        clip_scale=[]\n","        m=nn.Hardtanh(-1, 1)\n","        for index in range(self.num_of_params):\n","            clip_scale.append(m(Variable(self.target_modules[index].data)))\n","        for index in range(self.num_of_params):\n","            self.target_modules[index].data.copy_(clip_scale[index].data)"],"metadata":{"id":"NuEyGkJZ0w_6","executionInfo":{"status":"ok","timestamp":1705915116249,"user_tz":0,"elapsed":2,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def train_model(model, epoch, loss_fn, optimizer, bin_op):\n","  model.train()\n","  history = {'train_loss':[], 'train_accuracy':[], 'train_precision':[], 'train_recall':[], 'train_f1':[],\n","             'val_loss':[], 'val_accuracy':[], 'val_precision':[], 'val_recall':[], 'val_f1':[]}\n","\n","  for epoch in range(epoch):\n","\n","      model.train(True)\n","      running_loss = 0.0\n","      correct = 0\n","      output_list = None\n","      label_list = None\n","      for i, data in enumerate(train_dataloader, 0):\n","\n","          inputs, labels = data\n","          optimizer.zero_grad()\n","          outputs = model(inputs)\n","          labels = labels.long()\n","          #print(outputs)\n","          #bin_op.binarization()\n","          bin_op.BWN()\n","          loss = loss_fn(torch.log(outputs), labels)\n","          #print(loss)\n","          loss.backward()\n","          bin_op.restore()\n","          #print(loss)\n","          #print(model(inputs))\n","          optimizer.step()\n","          #bin_op.clip()\n","          #print('After optimisation',model(inputs))\n","          running_loss += loss.item()\n","          correct += (torch.argmax(outputs, dim=-1) == labels).float().sum()\n","          output_list = outputs if output_list is None else torch.cat((output_list,outputs),0)\n","          label_list = labels if label_list is None else torch.cat((label_list,labels),0)\n","\n","      avg_loss = running_loss / (i + 1)\n","      accuracy = correct / len(train_set)\n","      precision = multiclass_precision(output_list, label_list, num_classes=6, average='macro')\n","      recall = multiclass_recall(output_list, label_list, num_classes=6, average='macro')\n","      f1_score = multiclass_f1_score(output_list, label_list, num_classes=6, average='macro')\n","\n","      running_vloss = 0.0\n","      vcorrect = 0\n","      model.eval()\n","\n","      voutput_list = None\n","      vlabel_list = None\n","      with torch.no_grad():\n","          for i, vdata in enumerate(test_dataloader):\n","              vinputs, vlabels = vdata\n","              voutputs = model(vinputs)\n","              vloss = loss_fn(torch.log(voutputs), vlabels)\n","              running_vloss += vloss.item()\n","              vcorrect += (torch.argmax(voutputs, dim=-1) == vlabels).float().sum()\n","              voutput_list = voutputs if voutput_list is None else torch.cat((voutput_list,voutputs),0)\n","              vlabel_list = vlabels if vlabel_list is None else torch.cat((vlabel_list,vlabels),0)\n","\n","      avg_vloss = running_vloss / (i + 1)\n","      vaccuracy = vcorrect / len(test_set)\n","      vprecision = multiclass_precision(voutput_list, vlabel_list, num_classes=6, average='macro')\n","      vrecall = multiclass_recall(voutput_list, vlabel_list, num_classes=6, average='macro')\n","      vf1_score = multiclass_f1_score(voutput_list, vlabel_list, num_classes=6, average='macro')\n","\n","      print('Epoch {}-- Train loss:{:.2f} accuracy:{:.2f} precision:{:.2f} recall:{:.2f} f1:{:.2f}'.format(epoch, avg_loss, accuracy, precision, recall, f1_score))\n","      print('Epoch {}-- Valid loss:{:.2f} accuracy:{:.2f} precision:{:.2f} recall:{:.2f} f1:{:.2f}'.format(epoch, avg_vloss, vaccuracy, vprecision, vrecall, vf1_score))\n","      history['train_loss'].append(avg_loss)\n","      history['train_accuracy'].append(accuracy)\n","      history['train_precision'].append(precision)\n","      history['train_recall'].append(recall)\n","      history['train_f1'].append(f1_score)\n","      history['val_loss'].append(avg_vloss)\n","      history['val_accuracy'].append(vaccuracy)\n","      history['val_precision'].append(vprecision)\n","      history['val_recall'].append(vrecall)\n","      history['val_f1'].append(vf1_score)\n","\n","  return history\n","\n","def model_evaluate(model, bin_op):\n","    model.eval()\n","    voutput_list = None\n","    vlabel_list = None\n","    running_vloss = 0.0\n","    vcorrect = 0\n","    times = []\n","    with torch.no_grad():\n","        bin_op.BWN()\n","        #bin_op.binarization()\n","        for i, vdata in enumerate(test_dataloader):\n","            vinputs, vlabels = vdata\n","            vinputs = vinputs\n","            vlabels = vlabels\n","            start = time.time()\n","            voutputs = model(vinputs)\n","            end = time.time()\n","            times.append(end-start)\n","            #vloss = loss_fn(torch.log(voutputs), vlabels)\n","            #running_vloss += vloss.item()\n","            vcorrect += (torch.argmax(voutputs, dim=-1) == vlabels).float().sum()\n","            voutput_list = voutputs if voutput_list is None else torch.cat((voutput_list,voutputs),0)\n","            vlabel_list = vlabels if vlabel_list is None else torch.cat((vlabel_list,vlabels),0)\n","\n","    print(np.array(times).mean())\n","    bin_op.restore()\n","    avg_vloss = running_vloss / (i + 1)\n","    vaccuracy = vcorrect / len(test_set)\n","    vprecision = multiclass_precision(voutput_list, vlabel_list, num_classes=6, average='macro')\n","    vrecall = multiclass_recall(voutput_list, vlabel_list, num_classes=6, average='macro')\n","    vf1_score = multiclass_f1_score(voutput_list, vlabel_list, num_classes=6, average='macro')\n","    vauprc = multiclass_auprc(voutput_list, vlabel_list, num_classes=6, average='macro')\n","    vconfusion_matrix = multiclass_confusion_matrix(voutput_list, vlabel_list, num_classes=6, normalize=\"true\")\n","    vprc = multiclass_precision_recall_curve(voutput_list, vlabel_list, num_classes=6)\n","    analysis = {}\n","    analysis[\"loss\"] = avg_vloss\n","    analysis[\"accuracy\"] = vaccuracy\n","    analysis[\"precision\"] = vprecision\n","    analysis[\"recall\"] = vrecall\n","    analysis[\"f1_score\"] = vf1_score\n","    analysis[\"auprc\"] = vauprc\n","    analysis[\"confusion_matrix\"] = vconfusion_matrix\n","    analysis[\"prc\"] = vprc\n","    return analysis"],"metadata":{"id":"A7Zh-1slUr6G","executionInfo":{"status":"ok","timestamp":1705915481634,"user_tz":0,"elapsed":382,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["model = BaselineLSTM().to(device)\n","model.load_state_dict(torch.load('baselineLSTM_0122.pth'))\n","print('Number of model parameters: {}'.format(\n","    sum([p.data.nelement() for p in model.parameters()])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MsbqNPg0Smba","executionInfo":{"status":"ok","timestamp":1705915533837,"user_tz":0,"elapsed":3,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"818fc272-09fa-41ff-b048-0342f5cd57fe"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of model parameters: 9883330\n"]}]},{"cell_type":"code","source":["model = model.cuda()\n","bin_op = BC(model)\n","weights = torch.Tensor([20,20,1,10,10,10]).to(device)\n","#weights = torch.Tensor([1,1,1,1,1,1]).to(device)\n","loss_fn = nn.NLLLoss(weight=weights)\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)\n","history = train_model(model, 10, loss_fn, optimizer, bin_op)\n","model_evaluate(model, bin_op)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SqX2HdixS_of","executionInfo":{"status":"ok","timestamp":1705915662237,"user_tz":0,"elapsed":26152,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"72dc54a4-875f-467c-c7f9-cfe7f173a7cb"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 0-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","Epoch 1-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 1-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","Epoch 2-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 2-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","Epoch 3-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 3-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","Epoch 4-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 4-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","Epoch 5-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 5-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","Epoch 6-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 6-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","Epoch 7-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 7-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","Epoch 8-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 8-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","Epoch 9-- Train loss:0.00 accuracy:1.00 precision:1.00 recall:1.00 f1:1.00\n","Epoch 9-- Valid loss:0.47 accuracy:0.95 precision:0.93 recall:0.93 f1:0.93\n","0.025904178619384766\n"]},{"output_type":"execute_result","data":{"text/plain":["{'loss': 0.0,\n"," 'accuracy': tensor(0.5401, device='cuda:0'),\n"," 'precision': tensor(0.3325, device='cuda:0'),\n"," 'recall': tensor(0.3651, device='cuda:0'),\n"," 'f1_score': tensor(0.2915, device='cuda:0'),\n"," 'auprc': tensor(0.3711, device='cuda:0'),\n"," 'confusion_matrix': tensor([[0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.7500],\n","         [0.0769, 0.0000, 0.2308, 0.0000, 0.0769, 0.6154],\n","         [0.1011, 0.0000, 0.6517, 0.0730, 0.0169, 0.1573],\n","         [0.1905, 0.0000, 0.0952, 0.1429, 0.0476, 0.5238],\n","         [0.2069, 0.0000, 0.0690, 0.0690, 0.2414, 0.4138],\n","         [0.0476, 0.0000, 0.0476, 0.0000, 0.0000, 0.9048]], device='cuda:0'),\n"," 'prc': ([tensor([0.0438, 0.0440, 0.0441, 0.0443, 0.0444, 0.0446, 0.0448, 0.0449, 0.0451,\n","           0.0453, 0.0455, 0.0456, 0.0458, 0.0460, 0.0462, 0.0463, 0.0465, 0.0467,\n","           0.0469, 0.0471, 0.0472, 0.0474, 0.0476, 0.0478, 0.0480, 0.0482, 0.0484,\n","           0.0486, 0.0488, 0.0490, 0.0492, 0.0494, 0.0496, 0.0498, 0.0500, 0.0502,\n","           0.0504, 0.0506, 0.0508, 0.0511, 0.0513, 0.0515, 0.0517, 0.0519, 0.0522,\n","           0.0524, 0.0526, 0.0529, 0.0531, 0.0533, 0.0536, 0.0538, 0.0541, 0.0543,\n","           0.0545, 0.0548, 0.0550, 0.0553, 0.0556, 0.0558, 0.0561, 0.0563, 0.0566,\n","           0.0569, 0.0571, 0.0574, 0.0577, 0.0580, 0.0583, 0.0585, 0.0588, 0.0591,\n","           0.0594, 0.0597, 0.0600, 0.0603, 0.0606, 0.0609, 0.0612, 0.0615, 0.0619,\n","           0.0622, 0.0625, 0.0628, 0.0635, 0.0638, 0.0642, 0.0645, 0.0649, 0.0652,\n","           0.0656, 0.0659, 0.0663, 0.0667, 0.0670, 0.0674, 0.0678, 0.0682, 0.0686,\n","           0.0690, 0.0694, 0.0698, 0.0702, 0.0706, 0.0714, 0.0719, 0.0723, 0.0727,\n","           0.0732, 0.0736, 0.0741, 0.0745, 0.0750, 0.0755, 0.0759, 0.0764, 0.0769,\n","           0.0774, 0.0779, 0.0784, 0.0789, 0.0795, 0.0800, 0.0805, 0.0811, 0.0816,\n","           0.0822, 0.0828, 0.0833, 0.0839, 0.0845, 0.0851, 0.0857, 0.0863, 0.0876,\n","           0.0882, 0.0889, 0.0896, 0.0902, 0.0909, 0.0916, 0.0923, 0.0930, 0.0938,\n","           0.0945, 0.0952, 0.0960, 0.0968, 0.0976, 0.0984, 0.0992, 0.1000, 0.1008,\n","           0.1017, 0.1026, 0.1034, 0.1043, 0.1053, 0.1062, 0.1071, 0.1081, 0.1091,\n","           0.1101, 0.1111, 0.1121, 0.1132, 0.1143, 0.1154, 0.1165, 0.1176, 0.1188,\n","           0.1200, 0.1212, 0.1224, 0.1237, 0.1250, 0.1263, 0.1277, 0.1290, 0.1196,\n","           0.1209, 0.1222, 0.1236, 0.1136, 0.1149, 0.1163, 0.1176, 0.1190, 0.1205,\n","           0.1220, 0.1235, 0.1250, 0.1266, 0.1282, 0.1299, 0.1316, 0.1333, 0.1370,\n","           0.1389, 0.1408, 0.1429, 0.1449, 0.1471, 0.1493, 0.1515, 0.1538, 0.1562,\n","           0.1587, 0.1613, 0.1639, 0.1667, 0.1695, 0.1724, 0.1754, 0.1786, 0.1818,\n","           0.1852, 0.1923, 0.1765, 0.1800, 0.1837, 0.1875, 0.1915, 0.1957, 0.2000,\n","           0.2045, 0.1860, 0.1905, 0.1707, 0.1750, 0.1795, 0.1842, 0.1892, 0.1944,\n","           0.2000, 0.1765, 0.1818, 0.1875, 0.1935, 0.2000, 0.1724, 0.1429, 0.1111,\n","           0.1154, 0.1200, 0.1250, 0.1304, 0.1364, 0.1429, 0.1500, 0.1579, 0.1667,\n","           0.1176, 0.1250, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","          device='cuda:0'),\n","   tensor([0.0474, 0.0476, 0.0480, 0.0481, 0.0483, 0.0487, 0.0489, 0.0491, 0.0492,\n","           0.0494, 0.0496, 0.0498, 0.0500, 0.0502, 0.0504, 0.0506, 0.0508, 0.0510,\n","           0.0512, 0.0514, 0.0516, 0.0518, 0.0520, 0.0482, 0.0484, 0.0486, 0.0488,\n","           0.0490, 0.0492, 0.0494, 0.0496, 0.0498, 0.0500, 0.0502, 0.0504, 0.0506,\n","           0.0508, 0.0511, 0.0513, 0.0515, 0.0517, 0.0519, 0.0522, 0.0524, 0.0526,\n","           0.0529, 0.0531, 0.0533, 0.0536, 0.0538, 0.0541, 0.0543, 0.0548, 0.0550,\n","           0.0553, 0.0556, 0.0558, 0.0561, 0.0563, 0.0566, 0.0569, 0.0571, 0.0574,\n","           0.0577, 0.0580, 0.0583, 0.0585, 0.0588, 0.0591, 0.0594, 0.0597, 0.0600,\n","           0.0603, 0.0606, 0.0609, 0.0612, 0.0615, 0.0619, 0.0622, 0.0625, 0.0628,\n","           0.0632, 0.0635, 0.0638, 0.0642, 0.0645, 0.0649, 0.0652, 0.0656, 0.0659,\n","           0.0663, 0.0667, 0.0670, 0.0674, 0.0678, 0.0682, 0.0686, 0.0690, 0.0694,\n","           0.0698, 0.0702, 0.0706, 0.0710, 0.0714, 0.0719, 0.0723, 0.0727, 0.0732,\n","           0.0736, 0.0741, 0.0745, 0.0750, 0.0755, 0.0759, 0.0764, 0.0769, 0.0774,\n","           0.0779, 0.0784, 0.0789, 0.0795, 0.0800, 0.0805, 0.0816, 0.0822, 0.0828,\n","           0.0833, 0.0839, 0.0845, 0.0851, 0.0857, 0.0863, 0.0870, 0.0876, 0.0882,\n","           0.0889, 0.0821, 0.0827, 0.0833, 0.0840, 0.0846, 0.0853, 0.0866, 0.0873,\n","           0.0880, 0.0887, 0.0894, 0.0902, 0.0909, 0.0917, 0.0924, 0.0932, 0.0940,\n","           0.0862, 0.0870, 0.0877, 0.0885, 0.0893, 0.0901, 0.0909, 0.0826, 0.0833,\n","           0.0841, 0.0849, 0.0857, 0.0865, 0.0777, 0.0686, 0.0693, 0.0700, 0.0707,\n","           0.0714, 0.0722, 0.0729, 0.0737, 0.0745, 0.0753, 0.0761, 0.0769, 0.0778,\n","           0.0787, 0.0795, 0.0805, 0.0814, 0.0824, 0.0833, 0.0843, 0.0732, 0.0741,\n","           0.0759, 0.0769, 0.0779, 0.0789, 0.0800, 0.0811, 0.0685, 0.0694, 0.0704,\n","           0.0714, 0.0725, 0.0735, 0.0746, 0.0606, 0.0615, 0.0625, 0.0635, 0.0645,\n","           0.0656, 0.0667, 0.0678, 0.0690, 0.0702, 0.0714, 0.0727, 0.0741, 0.0755,\n","           0.0769, 0.0784, 0.0800, 0.0816, 0.0833, 0.0851, 0.0652, 0.0667, 0.0682,\n","           0.0698, 0.0714, 0.0732, 0.0750, 0.0769, 0.0789, 0.0811, 0.0833, 0.0857,\n","           0.0882, 0.0909, 0.0938, 0.0968, 0.1000, 0.1034, 0.1071, 0.1111, 0.1154,\n","           0.1200, 0.1250, 0.1304, 0.1364, 0.0952, 0.1000, 0.1053, 0.1111, 0.1176,\n","           0.1250, 0.1429, 0.1538, 0.1667, 0.1818, 0.2000, 0.2222, 0.2500, 0.2857,\n","           0.3333, 0.4000, 0.5000, 0.6667, 0.5000, 1.0000, 1.0000],\n","          device='cuda:0'),\n","   tensor([0.6496, 0.6520, 0.6544, 0.6568, 0.6543, 0.6567, 0.6592, 0.6617, 0.6642,\n","           0.6667, 0.6692, 0.6679, 0.6705, 0.6692, 0.6718, 0.6744, 0.6770, 0.6797,\n","           0.6784, 0.6811, 0.6838, 0.6865, 0.6892, 0.6920, 0.6908, 0.6895, 0.6923,\n","           0.6951, 0.6980, 0.7008, 0.7037, 0.7066, 0.7125, 0.7155, 0.7185, 0.7173,\n","           0.7161, 0.7149, 0.7179, 0.7167, 0.7198, 0.7186, 0.7217, 0.7249, 0.7237,\n","           0.7225, 0.7257, 0.7289, 0.7321, 0.7354, 0.7342, 0.7376, 0.7443, 0.7477,\n","           0.7512, 0.7546, 0.7581, 0.7570, 0.7559, 0.7594, 0.7630, 0.7667, 0.7703,\n","           0.7692, 0.7729, 0.7718, 0.7707, 0.7745, 0.7734, 0.7723, 0.7761, 0.7750,\n","           0.7789, 0.7828, 0.7868, 0.7908, 0.7949, 0.7990, 0.8031, 0.8021, 0.8063,\n","           0.8105, 0.8148, 0.8191, 0.8235, 0.8226, 0.8216, 0.8207, 0.8197, 0.8242,\n","           0.8287, 0.8278, 0.8324, 0.8315, 0.8362, 0.8352, 0.8400, 0.8448, 0.8497,\n","           0.8547, 0.8596, 0.8647, 0.8698, 0.8750, 0.8743, 0.8795, 0.8788, 0.8780,\n","           0.8773, 0.8827, 0.8820, 0.8875, 0.8868, 0.8861, 0.8917, 0.8910, 0.8968,\n","           0.8961, 0.8954, 0.8947, 0.8940, 0.8933, 0.8926, 0.8919, 0.8980, 0.8973,\n","           0.9034, 0.9097, 0.9161, 0.9155, 0.9149, 0.9214, 0.9209, 0.9203, 0.9197,\n","           0.9265, 0.9333, 0.9328, 0.9398, 0.9470, 0.9466, 0.9462, 0.9535, 0.9609,\n","           0.9603, 0.9680, 0.9677, 0.9675, 0.9754, 0.9752, 0.9833, 0.9832, 0.9831,\n","           0.9829, 0.9828, 0.9826, 0.9825, 0.9823, 0.9821, 0.9820, 0.9818, 0.9908,\n","           0.9907, 0.9907, 0.9906, 0.9905, 0.9904, 0.9903, 0.9902, 0.9901, 0.9900,\n","           0.9899, 0.9898, 0.9897, 0.9896, 0.9895, 0.9894, 0.9892, 0.9891, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n","          device='cuda:0'),\n","   tensor([0.0766, 0.0769, 0.0772, 0.0775, 0.0778, 0.0781, 0.0784, 0.0787, 0.0789,\n","           0.0792, 0.0795, 0.0798, 0.0802, 0.0805, 0.0808, 0.0811, 0.0814, 0.0817,\n","           0.0820, 0.0824, 0.0827, 0.0830, 0.0833, 0.0837, 0.0840, 0.0843, 0.0847,\n","           0.0850, 0.0854, 0.0857, 0.0861, 0.0864, 0.0868, 0.0871, 0.0875, 0.0879,\n","           0.0882, 0.0886, 0.0890, 0.0894, 0.0897, 0.0901, 0.0905, 0.0909, 0.0913,\n","           0.0917, 0.0921, 0.0925, 0.0929, 0.0933, 0.0938, 0.0942, 0.0946, 0.0950,\n","           0.0955, 0.0959, 0.0963, 0.0968, 0.0972, 0.0977, 0.0981, 0.0986, 0.0991,\n","           0.0995, 0.1000, 0.1005, 0.1010, 0.1014, 0.1019, 0.1024, 0.1029, 0.0985,\n","           0.0990, 0.0995, 0.1000, 0.1005, 0.1010, 0.1015, 0.1020, 0.1026, 0.1031,\n","           0.1036, 0.1042, 0.1047, 0.1053, 0.1058, 0.1070, 0.1075, 0.1081, 0.1087,\n","           0.1099, 0.1105, 0.1111, 0.1117, 0.1124, 0.1130, 0.1136, 0.1143, 0.1149,\n","           0.1163, 0.1170, 0.1176, 0.1183, 0.1131, 0.1138, 0.1145, 0.1152, 0.1159,\n","           0.1166, 0.1173, 0.1118, 0.1125, 0.1069, 0.1076, 0.1083, 0.1026, 0.0968,\n","           0.0974, 0.0980, 0.0987, 0.0927, 0.0933, 0.0940, 0.0946, 0.0952, 0.0959,\n","           0.0966, 0.0972, 0.0979, 0.0915, 0.0922, 0.0857, 0.0863, 0.0797, 0.0730,\n","           0.0735, 0.0667, 0.0672, 0.0602, 0.0606, 0.0611, 0.0615, 0.0620, 0.0625,\n","           0.0630, 0.0635, 0.0640, 0.0645, 0.0650, 0.0656, 0.0661, 0.0667, 0.0672,\n","           0.0678, 0.0684, 0.0690, 0.0609, 0.0619, 0.0625, 0.0631, 0.0636, 0.0642,\n","           0.0648, 0.0654, 0.0660, 0.0667, 0.0673, 0.0680, 0.0686, 0.0693, 0.0700,\n","           0.0707, 0.0714, 0.0722, 0.0729, 0.0737, 0.0745, 0.0753, 0.0761, 0.0769,\n","           0.0778, 0.0787, 0.0575, 0.0581, 0.0588, 0.0595, 0.0602, 0.0610, 0.0617,\n","           0.0633, 0.0513, 0.0519, 0.0526, 0.0533, 0.0541, 0.0548, 0.0556, 0.0563,\n","           0.0580, 0.0588, 0.0597, 0.0606, 0.0615, 0.0625, 0.0635, 0.0645, 0.0656,\n","           0.0667, 0.0678, 0.0690, 0.0702, 0.0714, 0.0727, 0.0741, 0.0755, 0.0769,\n","           0.0784, 0.0800, 0.0816, 0.0833, 0.0851, 0.0870, 0.0889, 0.0909, 0.0930,\n","           0.0952, 0.0976, 0.1000, 0.1026, 0.1053, 0.1081, 0.1111, 0.1143, 0.1176,\n","           0.1212, 0.0938, 0.0968, 0.1000, 0.1034, 0.1071, 0.1111, 0.1154, 0.1200,\n","           0.1250, 0.1304, 0.0909, 0.0952, 0.1000, 0.1053, 0.1111, 0.1176, 0.1250,\n","           0.1333, 0.1429, 0.1538, 0.1667, 0.1818, 0.1000, 0.1111, 0.1250, 0.1429,\n","           0.1667, 0.2000, 0.2500, 0.3333, 0.5000, 0.0000, 1.0000],\n","          device='cuda:0'),\n","   tensor([0.1058, 0.1062, 0.1066, 0.1070, 0.1074, 0.1078, 0.1086, 0.1090, 0.1094,\n","           0.1098, 0.1103, 0.1107, 0.1111, 0.1115, 0.1120, 0.1124, 0.1128, 0.1133,\n","           0.1137, 0.1142, 0.1146, 0.1151, 0.1155, 0.1160, 0.1165, 0.1169, 0.1174,\n","           0.1179, 0.1184, 0.1189, 0.1193, 0.1198, 0.1203, 0.1208, 0.1213, 0.1218,\n","           0.1229, 0.1234, 0.1239, 0.1245, 0.1250, 0.1255, 0.1261, 0.1266, 0.1272,\n","           0.1278, 0.1283, 0.1289, 0.1295, 0.1300, 0.1306, 0.1312, 0.1318, 0.1324,\n","           0.1330, 0.1336, 0.1343, 0.1349, 0.1355, 0.1362, 0.1368, 0.1374, 0.1381,\n","           0.1388, 0.1394, 0.1401, 0.1408, 0.1415, 0.1422, 0.1429, 0.1436, 0.1443,\n","           0.1450, 0.1457, 0.1465, 0.1472, 0.1480, 0.1487, 0.1495, 0.1503, 0.1510,\n","           0.1518, 0.1526, 0.1534, 0.1551, 0.1559, 0.1568, 0.1576, 0.1585, 0.1593,\n","           0.1602, 0.1611, 0.1620, 0.1629, 0.1638, 0.1648, 0.1657, 0.1667, 0.1676,\n","           0.1686, 0.1696, 0.1706, 0.1716, 0.1667, 0.1617, 0.1627, 0.1636, 0.1646,\n","           0.1656, 0.1667, 0.1677, 0.1688, 0.1698, 0.1709, 0.1720, 0.1667, 0.1677,\n","           0.1688, 0.1699, 0.1711, 0.1722, 0.1745, 0.1757, 0.1769, 0.1781, 0.1793,\n","           0.1806, 0.1818, 0.1831, 0.1844, 0.1857, 0.1871, 0.1884, 0.1898, 0.1912,\n","           0.1926, 0.1940, 0.1955, 0.1970, 0.1985, 0.2000, 0.2016, 0.2031, 0.2047,\n","           0.2063, 0.2080, 0.2097, 0.2114, 0.2131, 0.2149, 0.2167, 0.2185, 0.2203,\n","           0.2222, 0.2241, 0.2261, 0.2281, 0.2301, 0.2321, 0.2342, 0.2364, 0.2385,\n","           0.2315, 0.2336, 0.2358, 0.2381, 0.2404, 0.2427, 0.2451, 0.2376, 0.2400,\n","           0.2424, 0.2449, 0.2474, 0.2500, 0.2526, 0.2553, 0.2581, 0.2500, 0.2527,\n","           0.2556, 0.2584, 0.2614, 0.2644, 0.2674, 0.2706, 0.2738, 0.2771, 0.2805,\n","           0.2840, 0.2750, 0.2785, 0.2821, 0.2727, 0.2763, 0.2800, 0.2703, 0.2603,\n","           0.2639, 0.2714, 0.2754, 0.2794, 0.2836, 0.2727, 0.2615, 0.2656, 0.2698,\n","           0.2742, 0.2787, 0.2833, 0.2881, 0.2931, 0.2982, 0.3036, 0.3148, 0.3208,\n","           0.3269, 0.3333, 0.3400, 0.3265, 0.3333, 0.3191, 0.3261, 0.3333, 0.3182,\n","           0.3256, 0.3333, 0.3415, 0.3250, 0.3333, 0.3421, 0.3243, 0.3333, 0.3429,\n","           0.3235, 0.3333, 0.3438, 0.3548, 0.3667, 0.3793, 0.3929, 0.4074, 0.4231,\n","           0.4000, 0.3750, 0.3478, 0.3636, 0.3810, 0.3500, 0.3158, 0.3333, 0.3529,\n","           0.3125, 0.3333, 0.2857, 0.2308, 0.2500, 0.2727, 0.2000, 0.2222, 0.2500,\n","           0.2857, 0.1667, 0.2000, 0.2500, 0.3333, 0.0000, 0.0000, 1.0000],\n","          device='cuda:0'),\n","   tensor([0.0766, 0.0769, 0.0772, 0.0775, 0.0778, 0.0781, 0.0784, 0.0787, 0.0789,\n","           0.0792, 0.0795, 0.0798, 0.0802, 0.0805, 0.0808, 0.0811, 0.0814, 0.0817,\n","           0.0820, 0.0824, 0.0827, 0.0830, 0.0833, 0.0837, 0.0840, 0.0843, 0.0847,\n","           0.0850, 0.0854, 0.0857, 0.0861, 0.0864, 0.0868, 0.0871, 0.0875, 0.0879,\n","           0.0882, 0.0886, 0.0890, 0.0894, 0.0897, 0.0901, 0.0905, 0.0909, 0.0913,\n","           0.0917, 0.0921, 0.0925, 0.0929, 0.0933, 0.0938, 0.0942, 0.0946, 0.0950,\n","           0.0955, 0.0959, 0.0963, 0.0968, 0.0977, 0.0981, 0.0986, 0.0991, 0.0995,\n","           0.1000, 0.1005, 0.1010, 0.1014, 0.1019, 0.1024, 0.1029, 0.1034, 0.1040,\n","           0.1045, 0.1050, 0.1055, 0.1061, 0.1066, 0.1071, 0.1077, 0.1082, 0.1088,\n","           0.1094, 0.1099, 0.1105, 0.1111, 0.1117, 0.1123, 0.1129, 0.1135, 0.1141,\n","           0.1148, 0.1154, 0.1160, 0.1167, 0.1173, 0.1180, 0.1186, 0.1193, 0.1200,\n","           0.1207, 0.1221, 0.1228, 0.1235, 0.1243, 0.1250, 0.1257, 0.1265, 0.1273,\n","           0.1280, 0.1288, 0.1296, 0.1304, 0.1312, 0.1321, 0.1329, 0.1338, 0.1346,\n","           0.1355, 0.1364, 0.1373, 0.1382, 0.1391, 0.1400, 0.1409, 0.1419, 0.1429,\n","           0.1438, 0.1448, 0.1458, 0.1469, 0.1479, 0.1489, 0.1500, 0.1511, 0.1522,\n","           0.1533, 0.1544, 0.1556, 0.1567, 0.1579, 0.1591, 0.1603, 0.1615, 0.1641,\n","           0.1575, 0.1587, 0.1613, 0.1626, 0.1639, 0.1653, 0.1667, 0.1681, 0.1610,\n","           0.1624, 0.1652, 0.1667, 0.1681, 0.1696, 0.1712, 0.1727, 0.1743, 0.1759,\n","           0.1776, 0.1792, 0.1810, 0.1827, 0.1845, 0.1863, 0.1881, 0.1900, 0.1919,\n","           0.1939, 0.1959, 0.1979, 0.2000, 0.2021, 0.2043, 0.2065, 0.2088, 0.2111,\n","           0.2159, 0.2184, 0.2209, 0.2235, 0.2262, 0.2289, 0.2317, 0.2346, 0.2375,\n","           0.2405, 0.2436, 0.2468, 0.2500, 0.2533, 0.2568, 0.2603, 0.2639, 0.2676,\n","           0.2714, 0.2754, 0.2794, 0.2836, 0.2879, 0.2769, 0.2812, 0.2857, 0.2903,\n","           0.2951, 0.3000, 0.3051, 0.3103, 0.3158, 0.3214, 0.3273, 0.3333, 0.3396,\n","           0.3462, 0.3529, 0.3600, 0.3673, 0.3750, 0.3830, 0.3913, 0.4000, 0.4091,\n","           0.4186, 0.4286, 0.4390, 0.4250, 0.4103, 0.4211, 0.4324, 0.4444, 0.4571,\n","           0.4706, 0.4545, 0.4688, 0.4839, 0.5000, 0.5172, 0.5357, 0.5556, 0.5769,\n","           0.6000, 0.5833, 0.5652, 0.5455, 0.5714, 0.5500, 0.5789, 0.6111, 0.5625,\n","           0.5333, 0.5000, 0.4615, 0.5000, 0.4545, 0.4000, 0.3333, 0.3750, 0.4286,\n","           0.5000, 0.4000, 0.5000, 0.6667, 0.5000, 1.0000, 1.0000],\n","          device='cuda:0')],\n","  [tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9167,\n","           0.9167, 0.9167, 0.9167, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333,\n","           0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333,\n","           0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333,\n","           0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333, 0.8333,\n","           0.8333, 0.8333, 0.7500, 0.7500, 0.7500, 0.7500, 0.7500, 0.7500, 0.7500,\n","           0.7500, 0.6667, 0.6667, 0.5833, 0.5833, 0.5833, 0.5833, 0.5833, 0.5833,\n","           0.5833, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.4167, 0.3333, 0.2500,\n","           0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n","           0.1667, 0.1667, 0.0833, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","          device='cuda:0'),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231, 0.9231,\n","           0.9231, 0.8462, 0.8462, 0.8462, 0.8462, 0.8462, 0.8462, 0.8462, 0.8462,\n","           0.8462, 0.8462, 0.8462, 0.8462, 0.8462, 0.8462, 0.8462, 0.8462, 0.8462,\n","           0.7692, 0.7692, 0.7692, 0.7692, 0.7692, 0.7692, 0.7692, 0.6923, 0.6923,\n","           0.6923, 0.6923, 0.6923, 0.6923, 0.6154, 0.5385, 0.5385, 0.5385, 0.5385,\n","           0.5385, 0.5385, 0.5385, 0.5385, 0.5385, 0.5385, 0.5385, 0.5385, 0.5385,\n","           0.5385, 0.5385, 0.5385, 0.5385, 0.5385, 0.5385, 0.5385, 0.4615, 0.4615,\n","           0.4615, 0.4615, 0.4615, 0.4615, 0.4615, 0.4615, 0.3846, 0.3846, 0.3846,\n","           0.3846, 0.3846, 0.3846, 0.3846, 0.3077, 0.3077, 0.3077, 0.3077, 0.3077,\n","           0.3077, 0.3077, 0.3077, 0.3077, 0.3077, 0.3077, 0.3077, 0.3077, 0.3077,\n","           0.3077, 0.3077, 0.3077, 0.3077, 0.3077, 0.3077, 0.2308, 0.2308, 0.2308,\n","           0.2308, 0.2308, 0.2308, 0.2308, 0.2308, 0.2308, 0.2308, 0.2308, 0.2308,\n","           0.2308, 0.2308, 0.2308, 0.2308, 0.2308, 0.2308, 0.2308, 0.2308, 0.2308,\n","           0.2308, 0.2308, 0.2308, 0.2308, 0.1538, 0.1538, 0.1538, 0.1538, 0.1538,\n","           0.1538, 0.1538, 0.1538, 0.1538, 0.1538, 0.1538, 0.1538, 0.1538, 0.1538,\n","           0.1538, 0.1538, 0.1538, 0.1538, 0.0769, 0.0769, 0.0000],\n","          device='cuda:0'),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9888, 0.9888, 0.9888, 0.9888, 0.9888,\n","           0.9888, 0.9888, 0.9831, 0.9831, 0.9775, 0.9775, 0.9775, 0.9775, 0.9775,\n","           0.9719, 0.9719, 0.9719, 0.9719, 0.9719, 0.9719, 0.9663, 0.9607, 0.9607,\n","           0.9607, 0.9607, 0.9607, 0.9607, 0.9607, 0.9607, 0.9607, 0.9607, 0.9551,\n","           0.9494, 0.9438, 0.9438, 0.9382, 0.9382, 0.9326, 0.9326, 0.9326, 0.9270,\n","           0.9213, 0.9213, 0.9213, 0.9213, 0.9213, 0.9157, 0.9157, 0.9157, 0.9157,\n","           0.9157, 0.9157, 0.9157, 0.9101, 0.9045, 0.9045, 0.9045, 0.9045, 0.9045,\n","           0.8989, 0.8989, 0.8933, 0.8876, 0.8876, 0.8820, 0.8764, 0.8764, 0.8708,\n","           0.8708, 0.8708, 0.8708, 0.8708, 0.8708, 0.8708, 0.8708, 0.8652, 0.8652,\n","           0.8652, 0.8652, 0.8652, 0.8652, 0.8596, 0.8539, 0.8483, 0.8427, 0.8427,\n","           0.8427, 0.8371, 0.8371, 0.8315, 0.8315, 0.8258, 0.8258, 0.8258, 0.8258,\n","           0.8258, 0.8258, 0.8258, 0.8258, 0.8258, 0.8202, 0.8202, 0.8146, 0.8090,\n","           0.8034, 0.8034, 0.7978, 0.7978, 0.7921, 0.7865, 0.7865, 0.7809, 0.7809,\n","           0.7753, 0.7697, 0.7640, 0.7584, 0.7528, 0.7472, 0.7416, 0.7416, 0.7360,\n","           0.7360, 0.7360, 0.7360, 0.7303, 0.7247, 0.7247, 0.7191, 0.7135, 0.7079,\n","           0.7079, 0.7079, 0.7022, 0.7022, 0.7022, 0.6966, 0.6910, 0.6910, 0.6910,\n","           0.6798, 0.6798, 0.6742, 0.6685, 0.6685, 0.6629, 0.6629, 0.6573, 0.6517,\n","           0.6461, 0.6404, 0.6348, 0.6292, 0.6236, 0.6180, 0.6124, 0.6067, 0.6067,\n","           0.6011, 0.5955, 0.5899, 0.5843, 0.5787, 0.5730, 0.5674, 0.5618, 0.5562,\n","           0.5506, 0.5449, 0.5393, 0.5337, 0.5281, 0.5225, 0.5169, 0.5112, 0.5112,\n","           0.5056, 0.5000, 0.4944, 0.4888, 0.4831, 0.4775, 0.4719, 0.4663, 0.4607,\n","           0.4551, 0.4494, 0.4438, 0.4382, 0.4326, 0.4270, 0.4213, 0.4157, 0.4101,\n","           0.4045, 0.3989, 0.3933, 0.3876, 0.3820, 0.3764, 0.3708, 0.3652, 0.3596,\n","           0.3539, 0.3483, 0.3427, 0.3371, 0.3315, 0.3258, 0.3202, 0.3146, 0.3090,\n","           0.3034, 0.2978, 0.2921, 0.2865, 0.2809, 0.2697, 0.2640, 0.2584, 0.2528,\n","           0.2472, 0.2416, 0.2360, 0.2303, 0.2247, 0.2191, 0.2135, 0.2079, 0.2022,\n","           0.1966, 0.1910, 0.1854, 0.1798, 0.1742, 0.1685, 0.1629, 0.1573, 0.1517,\n","           0.1461, 0.1404, 0.1348, 0.1292, 0.1236, 0.1180, 0.1124, 0.1067, 0.1011,\n","           0.0955, 0.0899, 0.0843, 0.0787, 0.0730, 0.0674, 0.0618, 0.0562, 0.0506,\n","           0.0449, 0.0393, 0.0337, 0.0281, 0.0225, 0.0169, 0.0112, 0.0056, 0.0000],\n","          device='cuda:0'),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048,\n","           0.9048, 0.9048, 0.8571, 0.8571, 0.8095, 0.8095, 0.8095, 0.7619, 0.7143,\n","           0.7143, 0.7143, 0.7143, 0.6667, 0.6667, 0.6667, 0.6667, 0.6667, 0.6667,\n","           0.6667, 0.6667, 0.6667, 0.6190, 0.6190, 0.5714, 0.5714, 0.5238, 0.4762,\n","           0.4762, 0.4286, 0.4286, 0.3810, 0.3810, 0.3810, 0.3810, 0.3810, 0.3810,\n","           0.3810, 0.3810, 0.3810, 0.3810, 0.3810, 0.3810, 0.3810, 0.3810, 0.3810,\n","           0.3810, 0.3810, 0.3810, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n","           0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n","           0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n","           0.3333, 0.3333, 0.2381, 0.2381, 0.2381, 0.2381, 0.2381, 0.2381, 0.2381,\n","           0.2381, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n","           0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n","           0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n","           0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n","           0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905, 0.1905,\n","           0.1905, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429,\n","           0.1429, 0.1429, 0.0952, 0.0952, 0.0952, 0.0952, 0.0952, 0.0952, 0.0952,\n","           0.0952, 0.0952, 0.0952, 0.0952, 0.0952, 0.0476, 0.0476, 0.0476, 0.0476,\n","           0.0476, 0.0476, 0.0476, 0.0476, 0.0476, 0.0000, 0.0000],\n","          device='cuda:0'),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 0.9655, 0.9310, 0.9310, 0.9310, 0.9310,\n","           0.9310, 0.9310, 0.9310, 0.9310, 0.9310, 0.9310, 0.9310, 0.8966, 0.8966,\n","           0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966,\n","           0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966,\n","           0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966,\n","           0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966,\n","           0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966, 0.8966,\n","           0.8621, 0.8621, 0.8621, 0.8621, 0.8621, 0.8621, 0.8621, 0.8276, 0.8276,\n","           0.8276, 0.8276, 0.8276, 0.8276, 0.8276, 0.8276, 0.8276, 0.7931, 0.7931,\n","           0.7931, 0.7931, 0.7931, 0.7931, 0.7931, 0.7931, 0.7931, 0.7931, 0.7931,\n","           0.7931, 0.7586, 0.7586, 0.7586, 0.7241, 0.7241, 0.7241, 0.6897, 0.6552,\n","           0.6552, 0.6552, 0.6552, 0.6552, 0.6552, 0.6207, 0.5862, 0.5862, 0.5862,\n","           0.5862, 0.5862, 0.5862, 0.5862, 0.5862, 0.5862, 0.5862, 0.5862, 0.5862,\n","           0.5862, 0.5862, 0.5862, 0.5517, 0.5517, 0.5172, 0.5172, 0.5172, 0.4828,\n","           0.4828, 0.4828, 0.4828, 0.4483, 0.4483, 0.4483, 0.4138, 0.4138, 0.4138,\n","           0.3793, 0.3793, 0.3793, 0.3793, 0.3793, 0.3793, 0.3793, 0.3793, 0.3793,\n","           0.3448, 0.3103, 0.2759, 0.2759, 0.2759, 0.2414, 0.2069, 0.2069, 0.2069,\n","           0.1724, 0.1724, 0.1379, 0.1034, 0.1034, 0.1034, 0.0690, 0.0690, 0.0690,\n","           0.0690, 0.0345, 0.0345, 0.0345, 0.0345, 0.0000, 0.0000, 0.0000],\n","          device='cuda:0'),\n","   tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n","           0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9524, 0.9048,\n","           0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048,\n","           0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048,\n","           0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048,\n","           0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048,\n","           0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.9048,\n","           0.9048, 0.9048, 0.9048, 0.9048, 0.9048, 0.8571, 0.8571, 0.8571, 0.8571,\n","           0.8571, 0.8571, 0.8571, 0.8571, 0.8571, 0.8571, 0.8571, 0.8571, 0.8571,\n","           0.8571, 0.8571, 0.8571, 0.8571, 0.8571, 0.8571, 0.8571, 0.8571, 0.8571,\n","           0.8571, 0.8571, 0.8571, 0.8095, 0.7619, 0.7619, 0.7619, 0.7619, 0.7619,\n","           0.7619, 0.7143, 0.7143, 0.7143, 0.7143, 0.7143, 0.7143, 0.7143, 0.7143,\n","           0.7143, 0.6667, 0.6190, 0.5714, 0.5714, 0.5238, 0.5238, 0.5238, 0.4286,\n","           0.3810, 0.3333, 0.2857, 0.2857, 0.2381, 0.1905, 0.1429, 0.1429, 0.1429,\n","           0.1429, 0.0952, 0.0952, 0.0952, 0.0476, 0.0476, 0.0000],\n","          device='cuda:0')],\n","  [tensor([0.0030, 0.0063, 0.0089, 0.0093, 0.0120, 0.0123, 0.0128, 0.0129, 0.0145,\n","           0.0149, 0.0158, 0.0173, 0.0177, 0.0188, 0.0192, 0.0195, 0.0202, 0.0215,\n","           0.0220, 0.0224, 0.0224, 0.0225, 0.0231, 0.0235, 0.0237, 0.0241, 0.0248,\n","           0.0252, 0.0256, 0.0263, 0.0265, 0.0268, 0.0269, 0.0273, 0.0282, 0.0285,\n","           0.0286, 0.0296, 0.0305, 0.0306, 0.0308, 0.0308, 0.0312, 0.0315, 0.0316,\n","           0.0319, 0.0339, 0.0345, 0.0349, 0.0350, 0.0364, 0.0366, 0.0368, 0.0370,\n","           0.0371, 0.0376, 0.0395, 0.0396, 0.0396, 0.0409, 0.0411, 0.0424, 0.0426,\n","           0.0428, 0.0432, 0.0453, 0.0457, 0.0467, 0.0469, 0.0485, 0.0492, 0.0511,\n","           0.0518, 0.0534, 0.0535, 0.0556, 0.0592, 0.0594, 0.0645, 0.0681, 0.0686,\n","           0.0709, 0.0710, 0.0721, 0.0728, 0.0746, 0.0775, 0.0807, 0.0818, 0.0830,\n","           0.0834, 0.0858, 0.0868, 0.0883, 0.0894, 0.0905, 0.0943, 0.0947, 0.0960,\n","           0.0968, 0.0975, 0.0985, 0.0997, 0.1004, 0.1007, 0.1017, 0.1034, 0.1038,\n","           0.1137, 0.1142, 0.1170, 0.1188, 0.1221, 0.1228, 0.1235, 0.1257, 0.1267,\n","           0.1284, 0.1372, 0.1418, 0.1451, 0.1456, 0.1472, 0.1476, 0.1508, 0.1528,\n","           0.1570, 0.1580, 0.1585, 0.1603, 0.1611, 0.1616, 0.1631, 0.1638, 0.1664,\n","           0.1669, 0.1669, 0.1692, 0.1704, 0.1708, 0.1717, 0.1722, 0.1724, 0.1726,\n","           0.1734, 0.1734, 0.1740, 0.1744, 0.1774, 0.1781, 0.1791, 0.1815, 0.1852,\n","           0.1897, 0.1915, 0.1916, 0.1927, 0.1953, 0.1970, 0.1998, 0.2015, 0.2019,\n","           0.2038, 0.2042, 0.2069, 0.2074, 0.2079, 0.2090, 0.2113, 0.2131, 0.2147,\n","           0.2194, 0.2199, 0.2206, 0.2211, 0.2222, 0.2240, 0.2255, 0.2256, 0.2269,\n","           0.2275, 0.2285, 0.2287, 0.2288, 0.2306, 0.2309, 0.2315, 0.2328, 0.2356,\n","           0.2357, 0.2363, 0.2377, 0.2387, 0.2395, 0.2409, 0.2425, 0.2430, 0.2431,\n","           0.2439, 0.2444, 0.2472, 0.2484, 0.2486, 0.2497, 0.2506, 0.2518, 0.2523,\n","           0.2552, 0.2556, 0.2560, 0.2571, 0.2579, 0.2582, 0.2586, 0.2596, 0.2601,\n","           0.2605, 0.2622, 0.2633, 0.2674, 0.2675, 0.2699, 0.2704, 0.2754, 0.2787,\n","           0.2800, 0.2807, 0.2828, 0.2836, 0.2875, 0.2883, 0.2886, 0.2896, 0.2902,\n","           0.2909, 0.2912, 0.2913, 0.2919, 0.2953, 0.2954, 0.2971, 0.2989, 0.2997,\n","           0.2997, 0.2998, 0.3040, 0.3101, 0.3124, 0.3161, 0.3202, 0.3250, 0.3259,\n","           0.3264, 0.3308, 0.3370, 0.3377, 0.3420, 0.3487, 0.3501, 0.3652, 0.3870,\n","           0.4083, 0.4478, 0.4548, 0.4741, 0.5216, 0.6087], device='cuda:0'),\n","   tensor([0.0036, 0.0063, 0.0063, 0.0068, 0.0075, 0.0084, 0.0086, 0.0099, 0.0107,\n","           0.0110, 0.0115, 0.0116, 0.0116, 0.0120, 0.0124, 0.0141, 0.0145, 0.0149,\n","           0.0149, 0.0155, 0.0156, 0.0162, 0.0164, 0.0165, 0.0165, 0.0170, 0.0170,\n","           0.0174, 0.0174, 0.0175, 0.0176, 0.0179, 0.0179, 0.0182, 0.0182, 0.0182,\n","           0.0184, 0.0187, 0.0192, 0.0200, 0.0201, 0.0203, 0.0203, 0.0204, 0.0205,\n","           0.0208, 0.0209, 0.0213, 0.0214, 0.0215, 0.0215, 0.0218, 0.0223, 0.0224,\n","           0.0225, 0.0226, 0.0226, 0.0227, 0.0229, 0.0229, 0.0230, 0.0231, 0.0233,\n","           0.0235, 0.0235, 0.0237, 0.0238, 0.0240, 0.0240, 0.0241, 0.0243, 0.0244,\n","           0.0245, 0.0246, 0.0247, 0.0247, 0.0249, 0.0251, 0.0253, 0.0255, 0.0256,\n","           0.0258, 0.0258, 0.0259, 0.0266, 0.0266, 0.0267, 0.0267, 0.0268, 0.0270,\n","           0.0272, 0.0274, 0.0274, 0.0276, 0.0278, 0.0279, 0.0281, 0.0281, 0.0282,\n","           0.0287, 0.0289, 0.0291, 0.0291, 0.0294, 0.0295, 0.0296, 0.0296, 0.0298,\n","           0.0299, 0.0302, 0.0304, 0.0305, 0.0305, 0.0306, 0.0307, 0.0307, 0.0308,\n","           0.0310, 0.0310, 0.0311, 0.0313, 0.0316, 0.0318, 0.0318, 0.0322, 0.0322,\n","           0.0327, 0.0332, 0.0332, 0.0335, 0.0340, 0.0340, 0.0341, 0.0344, 0.0345,\n","           0.0346, 0.0347, 0.0347, 0.0347, 0.0350, 0.0351, 0.0351, 0.0354, 0.0355,\n","           0.0366, 0.0369, 0.0370, 0.0373, 0.0374, 0.0374, 0.0374, 0.0375, 0.0377,\n","           0.0381, 0.0383, 0.0383, 0.0385, 0.0385, 0.0387, 0.0390, 0.0392, 0.0392,\n","           0.0397, 0.0398, 0.0400, 0.0402, 0.0402, 0.0404, 0.0406, 0.0407, 0.0409,\n","           0.0410, 0.0415, 0.0419, 0.0419, 0.0425, 0.0425, 0.0428, 0.0435, 0.0437,\n","           0.0440, 0.0443, 0.0447, 0.0450, 0.0453, 0.0453, 0.0456, 0.0456, 0.0465,\n","           0.0467, 0.0488, 0.0491, 0.0498, 0.0510, 0.0512, 0.0512, 0.0519, 0.0522,\n","           0.0523, 0.0530, 0.0539, 0.0540, 0.0540, 0.0550, 0.0552, 0.0554, 0.0574,\n","           0.0575, 0.0576, 0.0580, 0.0587, 0.0589, 0.0606, 0.0607, 0.0609, 0.0622,\n","           0.0633, 0.0635, 0.0641, 0.0649, 0.0655, 0.0657, 0.0662, 0.0668, 0.0671,\n","           0.0676, 0.0678, 0.0683, 0.0700, 0.0701, 0.0714, 0.0718, 0.0720, 0.0720,\n","           0.0736, 0.0755, 0.0757, 0.0783, 0.0789, 0.0793, 0.0817, 0.0821, 0.0830,\n","           0.0831, 0.0832, 0.0851, 0.0859, 0.0864, 0.0910, 0.0924, 0.0946, 0.0965,\n","           0.0995, 0.1015, 0.1021, 0.1041, 0.1073, 0.1077, 0.1132, 0.1348, 0.1372,\n","           0.1410, 0.1429, 0.1506, 0.1624, 0.1665, 0.3387], device='cuda:0'),\n","   tensor([0.0658, 0.0719, 0.0800, 0.0834, 0.0900, 0.0924, 0.0940, 0.0950, 0.0967,\n","           0.1008, 0.1010, 0.1010, 0.1010, 0.1017, 0.1028, 0.1045, 0.1095, 0.1108,\n","           0.1109, 0.1110, 0.1128, 0.1136, 0.1144, 0.1171, 0.1184, 0.1201, 0.1213,\n","           0.1232, 0.1234, 0.1235, 0.1241, 0.1242, 0.1250, 0.1302, 0.1304, 0.1341,\n","           0.1344, 0.1367, 0.1382, 0.1387, 0.1397, 0.1412, 0.1413, 0.1414, 0.1419,\n","           0.1423, 0.1438, 0.1440, 0.1440, 0.1449, 0.1451, 0.1456, 0.1457, 0.1469,\n","           0.1513, 0.1520, 0.1527, 0.1539, 0.1540, 0.1550, 0.1574, 0.1579, 0.1592,\n","           0.1601, 0.1605, 0.1606, 0.1609, 0.1621, 0.1629, 0.1635, 0.1636, 0.1638,\n","           0.1667, 0.1671, 0.1682, 0.1703, 0.1706, 0.1724, 0.1732, 0.1754, 0.1754,\n","           0.1765, 0.1772, 0.1774, 0.1820, 0.1828, 0.1831, 0.1836, 0.1843, 0.1853,\n","           0.1853, 0.1866, 0.1873, 0.1876, 0.1876, 0.1879, 0.1892, 0.1894, 0.1925,\n","           0.1925, 0.1927, 0.1941, 0.1951, 0.1970, 0.1970, 0.1973, 0.1975, 0.1978,\n","           0.2014, 0.2023, 0.2034, 0.2042, 0.2047, 0.2047, 0.2052, 0.2079, 0.2117,\n","           0.2136, 0.2169, 0.2171, 0.2194, 0.2209, 0.2227, 0.2253, 0.2253, 0.2261,\n","           0.2265, 0.2265, 0.2266, 0.2294, 0.2312, 0.2463, 0.2527, 0.2527, 0.2551,\n","           0.2556, 0.2557, 0.2600, 0.2610, 0.2633, 0.2699, 0.2720, 0.2746, 0.2768,\n","           0.2776, 0.2804, 0.2842, 0.2847, 0.2855, 0.2865, 0.2894, 0.2897, 0.2918,\n","           0.2968, 0.2970, 0.3054, 0.3152, 0.3160, 0.3187, 0.3304, 0.3330, 0.3351,\n","           0.3507, 0.3519, 0.3521, 0.3612, 0.3704, 0.3738, 0.3814, 0.3826, 0.3832,\n","           0.3834, 0.3834, 0.3895, 0.3896, 0.3896, 0.3903, 0.3903, 0.3912, 0.3915,\n","           0.4037, 0.4063, 0.4183, 0.4192, 0.4226, 0.4274, 0.4281, 0.4298, 0.4338,\n","           0.4346, 0.4353, 0.4534, 0.4536, 0.4567, 0.4655, 0.4702, 0.4719, 0.4783,\n","           0.4790, 0.4791, 0.4817, 0.4836, 0.4842, 0.4845, 0.4864, 0.4930, 0.4974,\n","           0.5001, 0.5054, 0.5099, 0.5113, 0.5129, 0.5159, 0.5205, 0.5232, 0.5255,\n","           0.5308, 0.5337, 0.5350, 0.5467, 0.5487, 0.5503, 0.5546, 0.5547, 0.5590,\n","           0.5623, 0.5663, 0.5675, 0.5686, 0.5744, 0.5818, 0.5824, 0.5863, 0.5971,\n","           0.6003, 0.6059, 0.6075, 0.6098, 0.6139, 0.6242, 0.6246, 0.6296, 0.6327,\n","           0.6381, 0.6422, 0.6484, 0.6503, 0.6516, 0.6518, 0.6570, 0.6663, 0.6842,\n","           0.6876, 0.7118, 0.7137, 0.7181, 0.7299, 0.7358, 0.7399, 0.7410, 0.7436,\n","           0.7463, 0.7490, 0.7699, 0.7768, 0.8094, 0.8130, 0.8389, 0.8641],\n","          device='cuda:0'),\n","   tensor([0.0262, 0.0290, 0.0314, 0.0383, 0.0391, 0.0410, 0.0411, 0.0430, 0.0435,\n","           0.0451, 0.0498, 0.0505, 0.0505, 0.0506, 0.0534, 0.0538, 0.0555, 0.0562,\n","           0.0574, 0.0601, 0.0614, 0.0620, 0.0623, 0.0628, 0.0633, 0.0644, 0.0652,\n","           0.0664, 0.0668, 0.0669, 0.0673, 0.0678, 0.0684, 0.0690, 0.0691, 0.0692,\n","           0.0697, 0.0698, 0.0699, 0.0701, 0.0708, 0.0712, 0.0725, 0.0728, 0.0734,\n","           0.0736, 0.0740, 0.0741, 0.0744, 0.0748, 0.0755, 0.0756, 0.0767, 0.0774,\n","           0.0775, 0.0784, 0.0787, 0.0788, 0.0789, 0.0795, 0.0802, 0.0804, 0.0817,\n","           0.0819, 0.0819, 0.0820, 0.0820, 0.0821, 0.0828, 0.0829, 0.0832, 0.0840,\n","           0.0840, 0.0842, 0.0842, 0.0844, 0.0847, 0.0848, 0.0854, 0.0856, 0.0873,\n","           0.0876, 0.0884, 0.0887, 0.0887, 0.0888, 0.0889, 0.0904, 0.0907, 0.0912,\n","           0.0915, 0.0922, 0.0927, 0.0934, 0.0934, 0.0940, 0.0950, 0.0951, 0.0956,\n","           0.0956, 0.0958, 0.0961, 0.0969, 0.0971, 0.0973, 0.0973, 0.0985, 0.0987,\n","           0.0987, 0.0988, 0.0998, 0.1011, 0.1012, 0.1023, 0.1024, 0.1025, 0.1032,\n","           0.1040, 0.1045, 0.1046, 0.1056, 0.1071, 0.1072, 0.1078, 0.1086, 0.1093,\n","           0.1106, 0.1107, 0.1108, 0.1118, 0.1126, 0.1127, 0.1136, 0.1142, 0.1146,\n","           0.1181, 0.1185, 0.1187, 0.1206, 0.1224, 0.1242, 0.1244, 0.1245, 0.1249,\n","           0.1250, 0.1262, 0.1278, 0.1284, 0.1288, 0.1290, 0.1302, 0.1311, 0.1326,\n","           0.1335, 0.1346, 0.1360, 0.1374, 0.1391, 0.1406, 0.1407, 0.1408, 0.1423,\n","           0.1431, 0.1462, 0.1504, 0.1509, 0.1520, 0.1520, 0.1567, 0.1577, 0.1583,\n","           0.1590, 0.1594, 0.1600, 0.1620, 0.1622, 0.1627, 0.1641, 0.1658, 0.1671,\n","           0.1722, 0.1724, 0.1727, 0.1730, 0.1741, 0.1742, 0.1755, 0.1763, 0.1777,\n","           0.1832, 0.1845, 0.1870, 0.1885, 0.1922, 0.1952, 0.1972, 0.2019, 0.2028,\n","           0.2063, 0.2066, 0.2111, 0.2123, 0.2130, 0.2142, 0.2176, 0.2220, 0.2247,\n","           0.2291, 0.2309, 0.2349, 0.2371, 0.2380, 0.2398, 0.2398, 0.2404, 0.2414,\n","           0.2418, 0.2445, 0.2456, 0.2484, 0.2484, 0.2488, 0.2547, 0.2553, 0.2580,\n","           0.2611, 0.2620, 0.2663, 0.2685, 0.2697, 0.2755, 0.2761, 0.2789, 0.2815,\n","           0.2860, 0.2897, 0.2917, 0.2969, 0.3019, 0.3031, 0.3044, 0.3094, 0.3186,\n","           0.3254, 0.3294, 0.3300, 0.3314, 0.3376, 0.3382, 0.3414, 0.3553, 0.3645,\n","           0.3745, 0.3752, 0.3780, 0.3836, 0.4009, 0.4135, 0.4204, 0.4415, 0.4621,\n","           0.4662, 0.4733, 0.4818, 0.4954, 0.5527, 0.5670], device='cuda:0'),\n","   tensor([0.0104, 0.0132, 0.0134, 0.0203, 0.0223, 0.0249, 0.0300, 0.0302, 0.0304,\n","           0.0314, 0.0319, 0.0332, 0.0332, 0.0347, 0.0353, 0.0360, 0.0373, 0.0378,\n","           0.0387, 0.0393, 0.0404, 0.0414, 0.0416, 0.0419, 0.0436, 0.0445, 0.0448,\n","           0.0452, 0.0487, 0.0490, 0.0491, 0.0498, 0.0498, 0.0499, 0.0500, 0.0503,\n","           0.0504, 0.0522, 0.0528, 0.0534, 0.0537, 0.0542, 0.0547, 0.0550, 0.0563,\n","           0.0564, 0.0588, 0.0588, 0.0597, 0.0599, 0.0646, 0.0650, 0.0660, 0.0672,\n","           0.0673, 0.0673, 0.0684, 0.0685, 0.0687, 0.0697, 0.0739, 0.0747, 0.0758,\n","           0.0764, 0.0781, 0.0826, 0.0846, 0.0871, 0.0879, 0.0889, 0.0895, 0.0927,\n","           0.0935, 0.0940, 0.0940, 0.0945, 0.0955, 0.0958, 0.0963, 0.0994, 0.0998,\n","           0.1000, 0.1001, 0.1001, 0.1004, 0.1014, 0.1021, 0.1034, 0.1043, 0.1045,\n","           0.1063, 0.1067, 0.1075, 0.1093, 0.1100, 0.1104, 0.1105, 0.1108, 0.1113,\n","           0.1132, 0.1138, 0.1138, 0.1146, 0.1146, 0.1150, 0.1164, 0.1164, 0.1171,\n","           0.1178, 0.1190, 0.1197, 0.1202, 0.1206, 0.1210, 0.1218, 0.1219, 0.1223,\n","           0.1230, 0.1239, 0.1244, 0.1247, 0.1251, 0.1259, 0.1260, 0.1261, 0.1274,\n","           0.1280, 0.1284, 0.1286, 0.1293, 0.1295, 0.1302, 0.1303, 0.1307, 0.1312,\n","           0.1322, 0.1322, 0.1323, 0.1334, 0.1344, 0.1348, 0.1356, 0.1357, 0.1360,\n","           0.1361, 0.1364, 0.1369, 0.1372, 0.1373, 0.1373, 0.1376, 0.1382, 0.1383,\n","           0.1385, 0.1402, 0.1405, 0.1408, 0.1410, 0.1411, 0.1419, 0.1425, 0.1425,\n","           0.1429, 0.1438, 0.1443, 0.1444, 0.1445, 0.1457, 0.1469, 0.1471, 0.1479,\n","           0.1490, 0.1494, 0.1514, 0.1516, 0.1534, 0.1536, 0.1537, 0.1541, 0.1547,\n","           0.1548, 0.1558, 0.1558, 0.1560, 0.1560, 0.1560, 0.1565, 0.1573, 0.1573,\n","           0.1583, 0.1585, 0.1591, 0.1592, 0.1599, 0.1612, 0.1620, 0.1637, 0.1640,\n","           0.1642, 0.1647, 0.1651, 0.1651, 0.1652, 0.1653, 0.1672, 0.1678, 0.1681,\n","           0.1723, 0.1723, 0.1736, 0.1748, 0.1763, 0.1778, 0.1782, 0.1795, 0.1798,\n","           0.1802, 0.1807, 0.1844, 0.1858, 0.1863, 0.1872, 0.1888, 0.1891, 0.1897,\n","           0.1924, 0.1928, 0.1931, 0.1944, 0.1967, 0.1970, 0.1978, 0.1996, 0.2005,\n","           0.2086, 0.2142, 0.2143, 0.2184, 0.2218, 0.2219, 0.2221, 0.2261, 0.2312,\n","           0.2347, 0.2347, 0.2365, 0.2370, 0.2384, 0.2393, 0.2437, 0.2546, 0.2576,\n","           0.2589, 0.2661, 0.2664, 0.2671, 0.2809, 0.2889, 0.2934, 0.2991, 0.3371,\n","           0.3382, 0.3416, 0.3439, 0.3802, 0.3975, 0.4105, 0.4114],\n","          device='cuda:0'),\n","   tensor([0.0068, 0.0096, 0.0101, 0.0104, 0.0105, 0.0105, 0.0107, 0.0107, 0.0108,\n","           0.0115, 0.0115, 0.0119, 0.0124, 0.0132, 0.0137, 0.0143, 0.0147, 0.0154,\n","           0.0156, 0.0159, 0.0166, 0.0168, 0.0170, 0.0171, 0.0174, 0.0177, 0.0183,\n","           0.0188, 0.0195, 0.0198, 0.0202, 0.0211, 0.0212, 0.0217, 0.0220, 0.0223,\n","           0.0224, 0.0228, 0.0228, 0.0234, 0.0238, 0.0240, 0.0241, 0.0250, 0.0257,\n","           0.0261, 0.0261, 0.0277, 0.0283, 0.0287, 0.0302, 0.0307, 0.0310, 0.0311,\n","           0.0312, 0.0313, 0.0318, 0.0319, 0.0337, 0.0348, 0.0349, 0.0350, 0.0355,\n","           0.0359, 0.0360, 0.0373, 0.0373, 0.0376, 0.0381, 0.0397, 0.0405, 0.0415,\n","           0.0421, 0.0434, 0.0435, 0.0448, 0.0470, 0.0475, 0.0475, 0.0477, 0.0485,\n","           0.0500, 0.0500, 0.0505, 0.0516, 0.0527, 0.0530, 0.0549, 0.0551, 0.0559,\n","           0.0567, 0.0578, 0.0579, 0.0612, 0.0629, 0.0658, 0.0665, 0.0674, 0.0675,\n","           0.0737, 0.0748, 0.0781, 0.0798, 0.0800, 0.0808, 0.0822, 0.0827, 0.0859,\n","           0.0864, 0.0876, 0.0917, 0.0935, 0.0970, 0.0975, 0.1060, 0.1104, 0.1110,\n","           0.1116, 0.1177, 0.1183, 0.1223, 0.1229, 0.1253, 0.1259, 0.1268, 0.1273,\n","           0.1371, 0.1396, 0.1401, 0.1430, 0.1435, 0.1452, 0.1456, 0.1496, 0.1502,\n","           0.1572, 0.1575, 0.1628, 0.1677, 0.1734, 0.1752, 0.1780, 0.1813, 0.1827,\n","           0.1875, 0.1879, 0.1899, 0.1912, 0.1924, 0.1942, 0.1943, 0.1947, 0.2023,\n","           0.2024, 0.2025, 0.2032, 0.2083, 0.2117, 0.2118, 0.2120, 0.2141, 0.2150,\n","           0.2172, 0.2291, 0.2305, 0.2359, 0.2394, 0.2413, 0.2413, 0.2483, 0.2516,\n","           0.2539, 0.2547, 0.2623, 0.2624, 0.2639, 0.2647, 0.2686, 0.2725, 0.2749,\n","           0.2775, 0.2834, 0.2834, 0.2848, 0.2853, 0.2883, 0.2919, 0.2920, 0.2937,\n","           0.2972, 0.2983, 0.2994, 0.2999, 0.3014, 0.3040, 0.3047, 0.3050, 0.3079,\n","           0.3082, 0.3115, 0.3117, 0.3140, 0.3153, 0.3176, 0.3196, 0.3217, 0.3234,\n","           0.3275, 0.3281, 0.3291, 0.3300, 0.3301, 0.3302, 0.3342, 0.3361, 0.3415,\n","           0.3426, 0.3448, 0.3456, 0.3460, 0.3460, 0.3477, 0.3505, 0.3507, 0.3530,\n","           0.3540, 0.3570, 0.3584, 0.3596, 0.3613, 0.3627, 0.3630, 0.3633, 0.3660,\n","           0.3685, 0.3699, 0.3721, 0.3725, 0.3735, 0.3756, 0.3766, 0.3795, 0.3802,\n","           0.3825, 0.3840, 0.3845, 0.3859, 0.3877, 0.3936, 0.3949, 0.3951, 0.3953,\n","           0.3978, 0.4033, 0.4069, 0.4081, 0.4212, 0.4217, 0.4233, 0.4263, 0.4372,\n","           0.4451, 0.4451, 0.4470, 0.4501, 0.4911, 0.4920], device='cuda:0')])}"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["print_size_of_model(model)"],"metadata":{"id":"mbRIg8Wmf54_","executionInfo":{"status":"ok","timestamp":1705915712381,"user_tz":0,"elapsed":2,"user":{"displayName":"Xiaochen Zoey Tan","userId":"02061312605743465288"}},"outputId":"f491b1e5-4d5e-4ccf-ccd8-f45521783cb6","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Size (MB): 39.537877\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"eBEEofIcdgsY"},"execution_count":null,"outputs":[]}]}